{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"themes/maupassant/source/css/copycode.scss","path":"css/copycode.scss","modified":0,"renderable":1},{"_id":"themes/maupassant/source/css/copyright.scss","path":"css/copyright.scss","modified":0,"renderable":1},{"_id":"themes/maupassant/source/css/donate.scss","path":"css/donate.scss","modified":0,"renderable":1},{"_id":"themes/maupassant/source/css/search.scss","path":"css/search.scss","modified":0,"renderable":1},{"_id":"themes/maupassant/source/css/style.scss","path":"css/style.scss","modified":0,"renderable":1},{"_id":"themes/maupassant/source/img/alipay.svg","path":"img/alipay.svg","modified":0,"renderable":1},{"_id":"themes/maupassant/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"themes/maupassant/source/img/bitcoin.svg","path":"img/bitcoin.svg","modified":0,"renderable":1},{"_id":"themes/maupassant/source/img/github.svg","path":"img/github.svg","modified":0,"renderable":1},{"_id":"themes/maupassant/source/img/like.svg","path":"img/like.svg","modified":0,"renderable":1},{"_id":"themes/maupassant/source/img/paypal.svg","path":"img/paypal.svg","modified":0,"renderable":1},{"_id":"themes/maupassant/source/img/wechat.svg","path":"img/wechat.svg","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/codeblock-resizer.js","path":"js/codeblock-resizer.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/copycode.js","path":"js/copycode.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/copyright.js","path":"js/copyright.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/donate.js","path":"js/donate.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/fancybox.js","path":"js/fancybox.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/love.js","path":"js/love.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/recent-comments.js","path":"js/recent-comments.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/share.js","path":"js/share.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/smartresize.js","path":"js/smartresize.js","modified":0,"renderable":1},{"_id":"themes/maupassant/source/js/totop.js","path":"js/totop.js","modified":0,"renderable":1},{"_id":"source/pictures/crash-1.png","path":"pictures/crash-1.png","modified":0,"renderable":0},{"_id":"source/pictures/crash-2.png","path":"pictures/crash-2.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/CNAME","hash":"95dc3e44513daf1d0b024a693481b8323dd355f6","modified":1672125154753},{"_id":"source/_posts/ceph.md","hash":"950fba15e4906cbb1e27a6601dcc17cd059bfe05","modified":1672818846527},{"_id":"source/_posts/hello-world.md","hash":"7d98d6592de80fdcd2949bd7401cec12afd98cdf","modified":1672057603013},{"_id":"themes/maupassant/.gitignore","hash":"16945417d10c15c950306794dbb0d970b5a199fe","modified":1672124350713},{"_id":"themes/maupassant/.travis.yml","hash":"0339959f29deddc365e8fe8bd85da524410b9a23","modified":1672124350713},{"_id":"themes/maupassant/LICENSE","hash":"f0ac2f92770650c9835183f79010c0d307b34acd","modified":1672124350713},{"_id":"themes/maupassant/README.md","hash":"db11b1115c5c17e433104fae3767f99067a02c9d","modified":1672124350713},{"_id":"themes/maupassant/_config.yml","hash":"13b55194c556d5e0592fec4ac24d8b368283d86a","modified":1672124350713},{"_id":"themes/maupassant/package.json","hash":"f092433469eb87362e831326425a6a5c3c9fea0d","modified":1672124350713},{"_id":"themes/maupassant/languages/de-DE.yml","hash":"5d3556a885e355a8c2da65ef3e7b3ee36a628bfa","modified":1672124350713},{"_id":"themes/maupassant/languages/en.yml","hash":"27d8484ce29989317624e9852c5495289fe5501c","modified":1672124350713},{"_id":"themes/maupassant/languages/es-ES.yml","hash":"58e1d04bcd1834fa9d2960e18e027abbbccbedc9","modified":1672124350713},{"_id":"themes/maupassant/languages/fr-FR.yml","hash":"b47906ec0abf867fb3e3360bc046b7afb68aee25","modified":1672124350713},{"_id":"themes/maupassant/languages/ko.yml","hash":"909a33e0befa6978e8e72157c6b415b48551ee31","modified":1672124350713},{"_id":"themes/maupassant/languages/nb-NO.yml","hash":"dfef2a8f7582f9bccf7cf8376fb2b96c1e452d5f","modified":1672124350713},{"_id":"themes/maupassant/languages/ru.yml","hash":"2476a631f4d3c668de04af85a6c2c97ba2a57e96","modified":1672124350713},{"_id":"themes/maupassant/languages/zh-CN.yml","hash":"433484ab11838cc8540aceaf13eb718fa180ed9c","modified":1672124350713},{"_id":"themes/maupassant/languages/zh-TW.yml","hash":"58905c7fa82ee4f2232bcd00301dfcd7b711c61e","modified":1672124350713},{"_id":"themes/maupassant/layout/archive.pug","hash":"9bf5245929529576b5d6678142276adf3c221a6d","modified":1672124350713},{"_id":"themes/maupassant/layout/base-without-sidebar.pug","hash":"6b1ff15ae71223ef2cae1a56e40d2354cf40ff31","modified":1672124350713},{"_id":"themes/maupassant/layout/base.pug","hash":"ebfbb48e5f4b6810d5ea0b9e1bb252196ff698e8","modified":1672124350713},{"_id":"themes/maupassant/layout/blogroll.pug","hash":"31106223b01f45ab0b9747f91db104b0f0d1d4cc","modified":1672124350713},{"_id":"themes/maupassant/layout/index.pug","hash":"3e71a8b314b57a3e8b9f1d275c482361025afb23","modified":1672124350713},{"_id":"themes/maupassant/layout/page.pug","hash":"9b72086ff877de064f804a59684140af09470484","modified":1672124350713},{"_id":"themes/maupassant/layout/post.pug","hash":"d6672907918d43863ba88fbcbd4c9f3644270c99","modified":1672124350713},{"_id":"themes/maupassant/layout/tagcloud.pug","hash":"5c06b2a267070bd866b911cc894f314e97dfe2b4","modified":1672124350713},{"_id":"themes/maupassant/layout/timeline.pug","hash":"cef82a79f57e4e491f2934d990da939c4bebceb6","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/after_footer.pug","hash":"21fdb56fc42c5a250c04e92f49eb12ebcf0e2f3e","modified":1672124350713},{"_id":"themes/maupassant/layout/single-column.pug","hash":"0593f261dc208bb0b5c4232eb41eff597a291bd9","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/comments.pug","hash":"9af66c7df7d95f9397b0274c493918e9fdbf118f","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/darkmode.pug","hash":"82567449d68025cc7fee5259d4769f5ee015aa26","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/footer.pug","hash":"650781b5bc8c632658ad6880ba663b1e3bfb5798","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/head.pug","hash":"12d4aa97403f0bc5135e924b0b33251b0a1ad51d","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/helpers.pug","hash":"acdf9e2d52ee86c831fa15ce1570930c5779bc78","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/mathjax.pug","hash":"b54b56faff9e47ab3ca3cdd55056c73e60776f3c","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/mathjax2.pug","hash":"f91a71eb8a1af225a4f0f7749fedf534cc0ceae0","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/paginator.pug","hash":"53f9cb77448e84a98da5eb688e2e12b173c555bb","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/post_nav.pug","hash":"a2d698c84bb6da08195fe870dbd7215f65388d3f","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/tag.pug","hash":"1629fcab71affa9bac8112f4a46fc68e1567b505","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/totop.pug","hash":"8225bbc3cdb9648bc2e6872e5c616a9a1e4def4f","modified":1672124350713},{"_id":"themes/maupassant/layout/_partial/wordcount.pug","hash":"7dde69ef8f86745b83ba5f03c75717a782752f2b","modified":1672124350713},{"_id":"themes/maupassant/layout/_widget/category.pug","hash":"f2e9f6ff02b858b507f61768753b54846491f87a","modified":1672124350713},{"_id":"themes/maupassant/layout/_widget/copyright.pug","hash":"17e68ea3e87f128819d16ec30cd506a51fe80a7f","modified":1672124350713},{"_id":"themes/maupassant/layout/_widget/donate.pug","hash":"859eddafd2762072bc5af850038ff377578b0ce4","modified":1672124350713},{"_id":"themes/maupassant/layout/_widget/info.pug","hash":"82359802de5a4e3d80ec9a3737b071fd5c3be221","modified":1672124350713},{"_id":"themes/maupassant/layout/_widget/links.pug","hash":"3f6048423887f359bb97d17621e961495d209a7c","modified":1672124350713},{"_id":"themes/maupassant/layout/_widget/recent_comments.pug","hash":"e63c9f0a770324a03146fc263f3000c7cdc59631","modified":1672124350713},{"_id":"themes/maupassant/layout/_widget/recent_posts.pug","hash":"5a86fcd97933c665b5afef701d8b30cfd2952691","modified":1672124350713},{"_id":"themes/maupassant/layout/_widget/search.pug","hash":"a141293ce93b312f4db9f28207d02ee578ede359","modified":1672124350713},{"_id":"themes/maupassant/layout/_widget/tag.pug","hash":"9b73975ac67b471ae91803b8477932d2c5e5a4f2","modified":1672124350713},{"_id":"themes/maupassant/source/css/copycode.scss","hash":"e2463b8dacf629e180a1b6cd80667ca8044292eb","modified":1672124350713},{"_id":"themes/maupassant/source/css/copyright.scss","hash":"a418da11a88d1feb14500df42ed97a64da6a7611","modified":1672124350713},{"_id":"themes/maupassant/source/css/donate.scss","hash":"95b2fd65042afecc0b5530847c369bcc11d74bd0","modified":1672124350713},{"_id":"themes/maupassant/source/css/search.scss","hash":"9406e138d7bb6a9ef4a067eba1dafa627519c8a7","modified":1672124350713},{"_id":"themes/maupassant/source/css/style.scss","hash":"314b5e7b4da782b80f0458dcef7b9cdce27a0d2d","modified":1672124350713},{"_id":"themes/maupassant/source/img/alipay.svg","hash":"3d94d2f9b09e352802628c9225578e1086f5fef3","modified":1672124350713},{"_id":"themes/maupassant/source/img/avatar.png","hash":"00b5a5c68f9a65758ed063417830532ac9b26e04","modified":1672125453913},{"_id":"themes/maupassant/source/img/bitcoin.svg","hash":"590b6b6462896168d08b30dfe2de5f08950d5553","modified":1672124350713},{"_id":"themes/maupassant/source/img/github.svg","hash":"277798d16cb6106e45ef74f6b9972011fa43401b","modified":1672124350713},{"_id":"themes/maupassant/source/img/like.svg","hash":"e6e4bd1af076be9358316cac89efdc22ef4a5064","modified":1672124350713},{"_id":"themes/maupassant/source/img/paypal.svg","hash":"09786c983a10bc570dcd05b87cec601e9d01eb00","modified":1672124350713},{"_id":"themes/maupassant/source/img/wechat.svg","hash":"19c1f68ec8c0b8e9f7855e7a6e78077f70a1aedc","modified":1672124350713},{"_id":"themes/maupassant/source/js/codeblock-resizer.js","hash":"5d0b786d60bf225d9eabcc9cece2719ff4d9b6cd","modified":1672124350713},{"_id":"themes/maupassant/source/js/copycode.js","hash":"fde1f153bab1f00ae8930668094c00aa9ff3c7a3","modified":1672124350713},{"_id":"themes/maupassant/source/js/copyright.js","hash":"7b1bd775ea22abf33d57f78628f436bf656e439a","modified":1672124350713},{"_id":"themes/maupassant/source/js/donate.js","hash":"bdddd8d9847462d020f7a511e7e12c046223195d","modified":1672124350713},{"_id":"themes/maupassant/source/js/fancybox.js","hash":"13c4781570339f4fba76a3d7f202e442817dd605","modified":1672124350713},{"_id":"themes/maupassant/source/js/love.js","hash":"5cf89f622bf891cf1986845eb92eadef6f358eb7","modified":1672124350713},{"_id":"themes/maupassant/source/js/recent-comments.js","hash":"78708f86aa1fdcc003a056b1f91aac62d31bb012","modified":1672124350713},{"_id":"themes/maupassant/source/js/search.js","hash":"6fdfd143646d12b8dbef9b5809cea768192f08aa","modified":1672124350713},{"_id":"themes/maupassant/source/js/share.js","hash":"a2f9de374523dc7f2ddb90ed5f24b668c20d9272","modified":1672124350713},{"_id":"themes/maupassant/source/js/smartresize.js","hash":"3ef157fd877167e3290f42c67a624ea375a46c24","modified":1672124350713},{"_id":"themes/maupassant/source/js/totop.js","hash":"7dbf8fcf582a4fb6eb9b2c60d6de9f9c2091ec4c","modified":1672124350713},{"_id":"public/2022/12/26/ceph/index.html","hash":"a241aa902902d7913ca679e17fc3195e69ceb541","modified":1673829517153},{"_id":"public/2022/12/26/hello-world/index.html","hash":"d64929909a57fe1ef1e7c6cf2ae0e08f0ac2483d","modified":1672126307638},{"_id":"public/archives/index.html","hash":"c69cc33e125e58d51123c4fb9073a689b74ba17b","modified":1673829517153},{"_id":"public/archives/2022/index.html","hash":"cd7eea828c4fb4895854c845b08e2dd955329ebd","modified":1673829517153},{"_id":"public/archives/2022/12/index.html","hash":"cd7eea828c4fb4895854c845b08e2dd955329ebd","modified":1673829517153},{"_id":"public/index.html","hash":"b772b843fb3396aaeae1518fbab434f72564a4ad","modified":1673829517153},{"_id":"public/CNAME","hash":"95dc3e44513daf1d0b024a693481b8323dd355f6","modified":1672126307638},{"_id":"public/img/alipay.svg","hash":"3d94d2f9b09e352802628c9225578e1086f5fef3","modified":1672126307638},{"_id":"public/img/avatar.png","hash":"00b5a5c68f9a65758ed063417830532ac9b26e04","modified":1672126307638},{"_id":"public/img/bitcoin.svg","hash":"590b6b6462896168d08b30dfe2de5f08950d5553","modified":1672126307638},{"_id":"public/img/github.svg","hash":"277798d16cb6106e45ef74f6b9972011fa43401b","modified":1672126307638},{"_id":"public/img/like.svg","hash":"e6e4bd1af076be9358316cac89efdc22ef4a5064","modified":1672126307638},{"_id":"public/img/paypal.svg","hash":"09786c983a10bc570dcd05b87cec601e9d01eb00","modified":1672126307638},{"_id":"public/img/wechat.svg","hash":"19c1f68ec8c0b8e9f7855e7a6e78077f70a1aedc","modified":1672126307638},{"_id":"public/css/copycode.css","hash":"803d8bf898f47c3929665eb7af97da22f11efacd","modified":1672126307638},{"_id":"public/css/copyright.css","hash":"e857156bd1f971fe6abdc22d2b8c82e495387438","modified":1672126307638},{"_id":"public/css/donate.css","hash":"d631def20dfb661439c506f28dc791f331d506f8","modified":1672126307638},{"_id":"public/css/search.css","hash":"0d0f73b357c3bc5077ef657c73f679b22bea93fb","modified":1672126307638},{"_id":"public/js/codeblock-resizer.js","hash":"5d0b786d60bf225d9eabcc9cece2719ff4d9b6cd","modified":1672126307638},{"_id":"public/js/copycode.js","hash":"fde1f153bab1f00ae8930668094c00aa9ff3c7a3","modified":1672126307638},{"_id":"public/js/donate.js","hash":"bdddd8d9847462d020f7a511e7e12c046223195d","modified":1672126307638},{"_id":"public/js/copyright.js","hash":"7b1bd775ea22abf33d57f78628f436bf656e439a","modified":1672126307638},{"_id":"public/js/fancybox.js","hash":"13c4781570339f4fba76a3d7f202e442817dd605","modified":1672126307638},{"_id":"public/js/recent-comments.js","hash":"78708f86aa1fdcc003a056b1f91aac62d31bb012","modified":1672126307638},{"_id":"public/js/love.js","hash":"5cf89f622bf891cf1986845eb92eadef6f358eb7","modified":1672126307638},{"_id":"public/js/search.js","hash":"6fdfd143646d12b8dbef9b5809cea768192f08aa","modified":1672126307638},{"_id":"public/js/share.js","hash":"a2f9de374523dc7f2ddb90ed5f24b668c20d9272","modified":1672126307638},{"_id":"public/js/smartresize.js","hash":"3ef157fd877167e3290f42c67a624ea375a46c24","modified":1672126307638},{"_id":"public/js/totop.js","hash":"7dbf8fcf582a4fb6eb9b2c60d6de9f9c2091ec4c","modified":1672126307638},{"_id":"public/css/style.css","hash":"5f575fb9c7570c01910d53c8aa4997944f94cc6d","modified":1672126307638},{"_id":"source/_posts/word.md","hash":"30f700de353ca4918387c4c0fa14cbaf0a4142ac","modified":1672819098937},{"_id":"public/2023/01/04/word/index.html","hash":"4245cf4a1a6199a3e452289d51fd8aa1dfd4814b","modified":1673829517153},{"_id":"public/archives/2023/index.html","hash":"9b20c718c8083063323357a636465f85ba056490","modified":1673829517153},{"_id":"public/archives/2023/01/index.html","hash":"9b20c718c8083063323357a636465f85ba056490","modified":1673829517153},{"_id":"source/_posts/disk.md","hash":"df3103a1e57f0b6e68f68055fee59bbaeefa0812","modified":1673245555315},{"_id":"public/2023/01/09/disk/index.html","hash":"b10eb713edf0338a0f59b1b0ade6aa28d3747e3d","modified":1673829517153},{"_id":"source/_posts/crash工具使用.md","hash":"609ee7b4d9d4fc6fa313ac8dae0060d923202cfc","modified":1673685026553},{"_id":"source/_posts/快捷键备忘录.md","hash":"a8552ec8926d7084d78c14a254c125dcf2339f86","modified":1673763269793},{"_id":"public/2023/01/14/快捷键备忘录/index.html","hash":"4a4ec234d7398f12448a116a20f481a29b75fe8a","modified":1673829517153},{"_id":"public/2023/01/14/crash工具使用/index.html","hash":"8ea6a5d7ecd1baa9abb39fe0008cdb39dea62649","modified":1673685032794},{"_id":"source/pictures/crash-1.png","hash":"ddf09752d71c16a25318cc57874df21172e05ef2","modified":1673668447593},{"_id":"public/pictures/crash-1.png","hash":"ddf09752d71c16a25318cc57874df21172e05ef2","modified":1673668512734},{"_id":"source/pictures/crash-2.png","hash":"ff04408020afa1c6719a44bd637d2106b41e5a24","modified":1673672100863},{"_id":"public/pictures/crash-2.png","hash":"ff04408020afa1c6719a44bd637d2106b41e5a24","modified":1673672102858},{"_id":"source/_posts/一次mysql虚拟机crash分析.md","hash":"f501b712c7e283f537aeee0bc5acbc6dc3328396","modified":1673684092763},{"_id":"public/2023/01/14/一次mysql虚拟机crash分析/index.html","hash":"8f21f5b1780a5cd90f72144c3c7806292c1116ef","modified":1673829517153}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"ceph","date":"2022-12-26T12:36:11.000Z","_content":"\n# Ceph\n\n## OSD\n\n通常情况下一个OSD对应一块硬盘，每个OSD都拥有一个自己的Daemon。这个Daemon负责完成OSD的所有逻辑功能，包括Monitor和其他OSD（应该说是和其他OSD的Daemon）通信以更新系统状态，与他们OSD共同完成数据存储和维护，与Client通信以完成各种数据对象操作。\n\nRADOS集群从Ceph客户端（三种类型存储客户端 + librados自定义）接收数据并存储为对象。每个对象都是文件系统的一个文件，他们被存储在OSD的存储设备上，由OSD守护进程处理存储设备上的读写操作。\n\nOSD把所有数据存储为对象。对象包含一个标识符、二进制数据和由 `名称/值` 对组成的元数据。不同类型Ceph客户端元数据语义不同。\n\nino 待操作 File 的元数据，即文件唯一id\nono File 切割后某 Object 的序号\nOID （ino，ono）\n\n一个 File 被映射成多个 Object 后，需要把每个 Object 独立的映射到一个 PG 上。\n\nObject 的 size 应当被合理设置，通常为2或4MB\nPG也应该足够多，推荐为 OSD 的数百倍。\n\nPG -> OSD 的映射是多对多的，一个 PG 由 CRUSH 算法得到一组 OSD（共n个，n可配置）。  \n这n个OSD共同负责存储和维护一个 PG 中所有的 Object。\n\nCpeh 客户端在读写数据之前必须连个某个 ceph-mon ，获取最新的集群运行图副本。\n\nMon 不会主动轮询各个OSD的当前状态，OSD会主动上报。MON 收到信息后，会更新 Cluster Map 信息并加以扩散。\n\nPG 与 OSD 之间的映射关系通常是不变的，除非扩容、设备损坏、修改分配策略， CRUSH 会重新分配映射关系。\n\n这些的映射关系，使得一份文件被拆分并散列分步在不同OSD上，不仅有多份文件副本，还极大优化磁盘I/O性能。\n\n\n## Monitor\n\nMonitor是一个独立部署的daemon进程。通过组成Monitor集群来保证自己的高可用。Monitor集群通过Paxos算法实现了自己数据的一致性。它提供了整个存储系统的节点信息等全局的配置信息。\n\n## 数据平衡\n\n当在集群中新添加一个OSD存储设备时，整个集群会发生数据的迁移，使得数据分布达到均衡。Ceph数据迁移的基本单位是PG，即数据迁移是将PG中的所有对象作为一个整体来迁移。\n\n迁移触发的流程为：当新加入一个OSD时，会改变系统的CRUSH Map，从而引起对象寻址过程中的第二步，PG到OSD列表的映射发生了变化，从而引发数据的迁移。\n\n## Peering\n\n当OSD启动，或者某个OSD失效时，该OSD上的主PG会发起一个Peering的过程。Ceph的Peering过程是指一个PG内的所有副本通过PG日志来达成数据一致的过程。当Peering完成之后，该PG就可以对外提供读写服务了。此时PG的某些对象可能处于数据不一致的状态，其被标记出来，需要恢复。在写操作的过程中，遇到处于不一致的数据对象需要恢复的话，则需要等待，系统优先恢复该对象后，才能继续完成写操作。\n\n## Recovery和Backfill\n\nCeph的Recovery过程是根据在Peering的过程中产生的、依据PG日志推算出的不一致对象列表来修复其他副本上的数据。\nRecovery过程的依据是根据PG日志来推测出不一致的对象加以修复。当某个OSD长时间失效后重新加入集群，它已经无法根据PG日志来修复，就需要执行Backfill(回填)过程。Backfill过程是通过逐一对比两个PG的对象列表来修复。当新加入一个OSD产生了数据迁移，也需要通过Backfill过程来完成。\n\n## Scrub\n\nScrub机制用于系统检查数据的一致性。它通过在后台定期(默认每天一次)扫描，比较一个PG内的对象分别在其他OSD上的各个副本的元数据和数据来检查是否一致。根据扫描的内容分为两种，第一种是只比较对象各个副本的元数据，它代价比较小，扫描比较高效，对系统影响比较小。另一种扫描称为deep scrub，它需要进一步比较副本的数据内容检查数据是否一致。\n\n## osd的Flags\n\n### noin\n通常和noout一起用防止OSD up/down跳来跳去    \n\n### noout  \nMON在过了300秒(mon_osd_down_out_interval)后自动将down掉的OSD标记为out，一旦out数据就会开始迁移，建议在处理故障期间设置该标记，避免数据迁移。(故障处理的第一要则设置osd noout 防止数据迁移。ceph osd set noout ,ceph osd unset noout)\n\n### noup\n通常和nodwon一起用解决OSD up/down跳来跳去\n\n### nodown\n网络问题可能会影响到Ceph进程之间的心跳，有时候OSD进程还在,却被其他OSD一起举报标记为down,导致不必要的损耗，如果确定OSD进程始终正常可以设置nodown标记防止OSD被误标记为down.\n\n### full\n如果集群快要满了，你可以预先将其设置为FULL，注意这个设置会停止写操作。(有没有效需要实际测试)\n\n### pause\n这个标记会停止一切客户端的读写，但是集群依旧保持正常运行。\n\n### nobackfill\n\n### norebalance\n这个标记通常和上面的nobackfill和下面的norecover一起设置，在操作集群(挂掉OSD或者整个节点)时，如果不希望操作过程中数据发生恢复迁移等，可以设置这个标志，记得操作完后unset掉。\n\n### norecover\n也是在操作磁盘时防止数据发生恢复。\n\n### noscrub\nceph集群不做osd清理\n\n### nodeep-scrub\n有时候在集群恢复时，scrub操作会影响到恢复的性能，和上面的noscrub一起设置来停止scrub。一般不建议打开。\n\n### notieragent\n停止tier引擎查找冷数据并下刷到后端存储。\n\n### cpeh osd set {option}\n设置所有osd标志\n\n### ceph osd unset {option}\n接触所有osd标志\n\n### 使用下面的命令去修复pg和osd\n\n```\nceph osd repair ：修复一个特定的osd\nceph pg repair 修复一个特定的pg，可能会影响用户的数据，请谨慎使用。\nceph pg scrub：在指定的pg上做处理\nceph deep-scrub:在指定的pg上做深度清理。\nceph osd set pause 搬移机房时可以暂时停止读写，等待客户端读写完毕了，就可以关闭集群\n```\n\n## PG的States\n\n### Creating\n当创建一个池的时候，Ceph会创建一些PG(通俗点说就是在OSD上建目录)，处于创建中的PG就被标记为creating，当创建完之后，那些处于Acting集合(ceph pg map 1.0 osdmap e9395 pg 1.0 (1.0) -> up [27,4,10] acting [27,4,10]，对于pg它的三副本会分布在osd.27,osd.4,osd.10上，那么这三个OSD上的pg1.0就会发生沟通，确保状态一致)的PG就会进行peer(osd互联)，当peering完成后，也就是这个PG的三副本状态一致后，这个PG就会变成active+clean状态，也就意味着客户端可以进行写入操作了。\n\n### Peering\npeer过程实际上就是让三个保存同一个PG副本的OSD对保存在各自OSD上的对象状态和元数据进行协商的过程，但是呢peer完成并不意味着每个副本都保存着最新的数据。直到OSD的副本都完成写操作，Ceph才会通知客户端写操作完成。这确保了Acting集合中至少有一个副本，自最后一次成功的peer后。剩下的不好翻译因为没怎么理解。（对象和元数据的状态达成一致的过程。）\n\n### Active\n当PG完成了Peer之后，就会成为active状态，这个状态意味着主从OSD的该PG都可以提供读写了。\n\n### Clean\n这个状态的意思就是主从OSD已经成功peer并且没有滞后的副本。PG的正常副本数满足集群副本数。\n\n### Degraded\n当客户端向一个主OSD写入一个对象时，主OSD负责向从OSD写剩下的副本， 在主OSD写完后,在从OSD向主OSD发送ack之前，这个PG均会处于降级状态。而PG处于active+degraded状态是因为一个OSD处于active状态但是这个OSD上的PG并没有保存所有的对象。当一个OSDdown了，Ceph会将这个OSD上的PG都标记为降级。当这个挂掉的OSD重新上线之后，OSD们必须重新peer。然后，客户端还是可以向一个active+degraded的PG写入的。当OSDdown掉五分钟后，集群会自动将这个OSD标为out,然后将缺少的PGremap到其他OSD上进行恢复以保证副本充足，这个五分钟的配置项是mon osd down out interval，默认值为300s。\nPG如果丢了对象，Ceph也会将其标记为降级。你可以继续访问没丢的对象，但是不能读写已经丢失的对象了。假设有9个OSD，三副本，然后osd.8挂了，在osd.8上的PG都会被标记为降级，如果osd.8不再加回到集群那么集群就会自动恢复出那个OSD上的数据，在这个场景中，PG是降级的然后恢复完后就会变成active状态。\n\n### Recovering\nCeph设计之初就考虑到了容错性，比如软硬件的错误。当一个OSD挂了，它所包含的副本内容将会落后于其他副本，当这个OSD起来之后，这个OSD的数据将会更新到当前最新的状态。这段时间，这个OSD上的PG就会被标记为recover。而recover是不容忽视的，因为有时候一个小的硬件故障可能会导致多个OSD发生一连串的问题。比如，如果一个机架或者机柜的路由挂了，会导致一大批OSD数据滞后，每个OSD在故障解决重新上线后都需要进行recover。Ceph提供了一些配置项，用来解决客户端请求和数据恢复的请求优先级问题，这些配置参考上面加粗的字体吧。\n\n### Backfilling\n当一个新的OSD加入到集群后，CRUSH会重新规划PG将其他OSD上的部分PG迁移到这个新增的PG上。如果强制要求新OSD接受所有的PG迁入要求会极大的增加该OSD的负载。回填这个OSD允许进程在后端执行。一旦回填完成后，新的OSD将会承接IO请求。在回填过程中，你可能会看到如下状态：\n\n```\nbackfill_wait: 表明回填动作被挂起，并没有执行。\n\nbackfill：表明回填动作正在执行。\n\nbackfill_too_full：表明当OSD收到回填请求时，由于OSD已经满了不能再回填PG了。 \n\nimcomplete: 当一个PG不能被回填时，这个PG会被认为是不完整的。同样，Ceph提供了一系列的参数来限制回填动作，包括osd_max_backfills：OSD最大回填PG数。\n\nsd_backfill_full_ratio：当OSD容量达到默认的85%是拒绝回填请求。osd_backfill_retry_interval:字面意思。\nRemmapped   当Acting集合里面的PG组合发生变化时，数据从旧的集合迁移到新的集合中。这段时间可能比较久，新集合的主OSD在迁移完之前不能响应请求。所以新主OSD会要求旧主OSD继续服务指导PG迁移完成。一旦数据迁移完成，新主OSD就会生效接受请求。\n```\n\n### Stale\nCeph使用心跳来确保主机和进程都在运行，OSD进程如果不能周期性的发送心跳包，那么PG就会变成stuck状态。默认情况下，OSD每半秒钟汇报一次PG，up thru,boot, failure statistics等信息，要比心跳包更会频繁一点。如果主OSD不能汇报给MON或者其他OSD汇报主OSD挂了，Monitor会将主OSD上的PG标记为stale。当启动集群后，直到peer过程完成，PG都会处于stale状态。而当集群运行了一段时间后，如果PG卡在stale状态，说明主OSD上的PG挂了或者不能给MON发送信息。\n\n### Misplaced\n有一些回填的场景：PG被临时映射到一个OSD上。而这种情况实际上不应太久，PG可能仍然处于临时位置而不是正确的位置。这种情况下个PG就是misplaced。这是因为正确的副本数存在但是有个别副本保存在错误的位置上。\n\n### Incomplete\n当一个PG被标记为incomplete,说明这个PG内容不完整或者peer失败，比如没有一个完整的OSD用来恢复数据了。\n\n### scrubbing\n清理中，pg正在做不一致性校验。\n\n### inconsistent\n不一致的，pg的副本出现不一致。比如说对象的大小不一样了。\n\n\n## 卡住的pg状态： \n```\nUnclean: 归置组里有些对象的副本数未达到期望次数，它们应该在恢复中； \nInactive: 归置组不能处理读写请求，因为它们在等着一个持有最新数据的OSD 回到up 状态； \nStale: 归置组们处于一种未知状态，因为存储它们的OSD 有一阵子没向监视器报告了（由mon osd report timeout 配置） \n为找出卡住的归置组，执行：\nceph pg dump_stuck [unclean|inactive|stale|undersized|degraded]\n```\n","source":"_posts/ceph.md","raw":"---\ntitle: ceph\ndate: 2022-12-26 20:36:11\ntags:\n---\n\n# Ceph\n\n## OSD\n\n通常情况下一个OSD对应一块硬盘，每个OSD都拥有一个自己的Daemon。这个Daemon负责完成OSD的所有逻辑功能，包括Monitor和其他OSD（应该说是和其他OSD的Daemon）通信以更新系统状态，与他们OSD共同完成数据存储和维护，与Client通信以完成各种数据对象操作。\n\nRADOS集群从Ceph客户端（三种类型存储客户端 + librados自定义）接收数据并存储为对象。每个对象都是文件系统的一个文件，他们被存储在OSD的存储设备上，由OSD守护进程处理存储设备上的读写操作。\n\nOSD把所有数据存储为对象。对象包含一个标识符、二进制数据和由 `名称/值` 对组成的元数据。不同类型Ceph客户端元数据语义不同。\n\nino 待操作 File 的元数据，即文件唯一id\nono File 切割后某 Object 的序号\nOID （ino，ono）\n\n一个 File 被映射成多个 Object 后，需要把每个 Object 独立的映射到一个 PG 上。\n\nObject 的 size 应当被合理设置，通常为2或4MB\nPG也应该足够多，推荐为 OSD 的数百倍。\n\nPG -> OSD 的映射是多对多的，一个 PG 由 CRUSH 算法得到一组 OSD（共n个，n可配置）。  \n这n个OSD共同负责存储和维护一个 PG 中所有的 Object。\n\nCpeh 客户端在读写数据之前必须连个某个 ceph-mon ，获取最新的集群运行图副本。\n\nMon 不会主动轮询各个OSD的当前状态，OSD会主动上报。MON 收到信息后，会更新 Cluster Map 信息并加以扩散。\n\nPG 与 OSD 之间的映射关系通常是不变的，除非扩容、设备损坏、修改分配策略， CRUSH 会重新分配映射关系。\n\n这些的映射关系，使得一份文件被拆分并散列分步在不同OSD上，不仅有多份文件副本，还极大优化磁盘I/O性能。\n\n\n## Monitor\n\nMonitor是一个独立部署的daemon进程。通过组成Monitor集群来保证自己的高可用。Monitor集群通过Paxos算法实现了自己数据的一致性。它提供了整个存储系统的节点信息等全局的配置信息。\n\n## 数据平衡\n\n当在集群中新添加一个OSD存储设备时，整个集群会发生数据的迁移，使得数据分布达到均衡。Ceph数据迁移的基本单位是PG，即数据迁移是将PG中的所有对象作为一个整体来迁移。\n\n迁移触发的流程为：当新加入一个OSD时，会改变系统的CRUSH Map，从而引起对象寻址过程中的第二步，PG到OSD列表的映射发生了变化，从而引发数据的迁移。\n\n## Peering\n\n当OSD启动，或者某个OSD失效时，该OSD上的主PG会发起一个Peering的过程。Ceph的Peering过程是指一个PG内的所有副本通过PG日志来达成数据一致的过程。当Peering完成之后，该PG就可以对外提供读写服务了。此时PG的某些对象可能处于数据不一致的状态，其被标记出来，需要恢复。在写操作的过程中，遇到处于不一致的数据对象需要恢复的话，则需要等待，系统优先恢复该对象后，才能继续完成写操作。\n\n## Recovery和Backfill\n\nCeph的Recovery过程是根据在Peering的过程中产生的、依据PG日志推算出的不一致对象列表来修复其他副本上的数据。\nRecovery过程的依据是根据PG日志来推测出不一致的对象加以修复。当某个OSD长时间失效后重新加入集群，它已经无法根据PG日志来修复，就需要执行Backfill(回填)过程。Backfill过程是通过逐一对比两个PG的对象列表来修复。当新加入一个OSD产生了数据迁移，也需要通过Backfill过程来完成。\n\n## Scrub\n\nScrub机制用于系统检查数据的一致性。它通过在后台定期(默认每天一次)扫描，比较一个PG内的对象分别在其他OSD上的各个副本的元数据和数据来检查是否一致。根据扫描的内容分为两种，第一种是只比较对象各个副本的元数据，它代价比较小，扫描比较高效，对系统影响比较小。另一种扫描称为deep scrub，它需要进一步比较副本的数据内容检查数据是否一致。\n\n## osd的Flags\n\n### noin\n通常和noout一起用防止OSD up/down跳来跳去    \n\n### noout  \nMON在过了300秒(mon_osd_down_out_interval)后自动将down掉的OSD标记为out，一旦out数据就会开始迁移，建议在处理故障期间设置该标记，避免数据迁移。(故障处理的第一要则设置osd noout 防止数据迁移。ceph osd set noout ,ceph osd unset noout)\n\n### noup\n通常和nodwon一起用解决OSD up/down跳来跳去\n\n### nodown\n网络问题可能会影响到Ceph进程之间的心跳，有时候OSD进程还在,却被其他OSD一起举报标记为down,导致不必要的损耗，如果确定OSD进程始终正常可以设置nodown标记防止OSD被误标记为down.\n\n### full\n如果集群快要满了，你可以预先将其设置为FULL，注意这个设置会停止写操作。(有没有效需要实际测试)\n\n### pause\n这个标记会停止一切客户端的读写，但是集群依旧保持正常运行。\n\n### nobackfill\n\n### norebalance\n这个标记通常和上面的nobackfill和下面的norecover一起设置，在操作集群(挂掉OSD或者整个节点)时，如果不希望操作过程中数据发生恢复迁移等，可以设置这个标志，记得操作完后unset掉。\n\n### norecover\n也是在操作磁盘时防止数据发生恢复。\n\n### noscrub\nceph集群不做osd清理\n\n### nodeep-scrub\n有时候在集群恢复时，scrub操作会影响到恢复的性能，和上面的noscrub一起设置来停止scrub。一般不建议打开。\n\n### notieragent\n停止tier引擎查找冷数据并下刷到后端存储。\n\n### cpeh osd set {option}\n设置所有osd标志\n\n### ceph osd unset {option}\n接触所有osd标志\n\n### 使用下面的命令去修复pg和osd\n\n```\nceph osd repair ：修复一个特定的osd\nceph pg repair 修复一个特定的pg，可能会影响用户的数据，请谨慎使用。\nceph pg scrub：在指定的pg上做处理\nceph deep-scrub:在指定的pg上做深度清理。\nceph osd set pause 搬移机房时可以暂时停止读写，等待客户端读写完毕了，就可以关闭集群\n```\n\n## PG的States\n\n### Creating\n当创建一个池的时候，Ceph会创建一些PG(通俗点说就是在OSD上建目录)，处于创建中的PG就被标记为creating，当创建完之后，那些处于Acting集合(ceph pg map 1.0 osdmap e9395 pg 1.0 (1.0) -> up [27,4,10] acting [27,4,10]，对于pg它的三副本会分布在osd.27,osd.4,osd.10上，那么这三个OSD上的pg1.0就会发生沟通，确保状态一致)的PG就会进行peer(osd互联)，当peering完成后，也就是这个PG的三副本状态一致后，这个PG就会变成active+clean状态，也就意味着客户端可以进行写入操作了。\n\n### Peering\npeer过程实际上就是让三个保存同一个PG副本的OSD对保存在各自OSD上的对象状态和元数据进行协商的过程，但是呢peer完成并不意味着每个副本都保存着最新的数据。直到OSD的副本都完成写操作，Ceph才会通知客户端写操作完成。这确保了Acting集合中至少有一个副本，自最后一次成功的peer后。剩下的不好翻译因为没怎么理解。（对象和元数据的状态达成一致的过程。）\n\n### Active\n当PG完成了Peer之后，就会成为active状态，这个状态意味着主从OSD的该PG都可以提供读写了。\n\n### Clean\n这个状态的意思就是主从OSD已经成功peer并且没有滞后的副本。PG的正常副本数满足集群副本数。\n\n### Degraded\n当客户端向一个主OSD写入一个对象时，主OSD负责向从OSD写剩下的副本， 在主OSD写完后,在从OSD向主OSD发送ack之前，这个PG均会处于降级状态。而PG处于active+degraded状态是因为一个OSD处于active状态但是这个OSD上的PG并没有保存所有的对象。当一个OSDdown了，Ceph会将这个OSD上的PG都标记为降级。当这个挂掉的OSD重新上线之后，OSD们必须重新peer。然后，客户端还是可以向一个active+degraded的PG写入的。当OSDdown掉五分钟后，集群会自动将这个OSD标为out,然后将缺少的PGremap到其他OSD上进行恢复以保证副本充足，这个五分钟的配置项是mon osd down out interval，默认值为300s。\nPG如果丢了对象，Ceph也会将其标记为降级。你可以继续访问没丢的对象，但是不能读写已经丢失的对象了。假设有9个OSD，三副本，然后osd.8挂了，在osd.8上的PG都会被标记为降级，如果osd.8不再加回到集群那么集群就会自动恢复出那个OSD上的数据，在这个场景中，PG是降级的然后恢复完后就会变成active状态。\n\n### Recovering\nCeph设计之初就考虑到了容错性，比如软硬件的错误。当一个OSD挂了，它所包含的副本内容将会落后于其他副本，当这个OSD起来之后，这个OSD的数据将会更新到当前最新的状态。这段时间，这个OSD上的PG就会被标记为recover。而recover是不容忽视的，因为有时候一个小的硬件故障可能会导致多个OSD发生一连串的问题。比如，如果一个机架或者机柜的路由挂了，会导致一大批OSD数据滞后，每个OSD在故障解决重新上线后都需要进行recover。Ceph提供了一些配置项，用来解决客户端请求和数据恢复的请求优先级问题，这些配置参考上面加粗的字体吧。\n\n### Backfilling\n当一个新的OSD加入到集群后，CRUSH会重新规划PG将其他OSD上的部分PG迁移到这个新增的PG上。如果强制要求新OSD接受所有的PG迁入要求会极大的增加该OSD的负载。回填这个OSD允许进程在后端执行。一旦回填完成后，新的OSD将会承接IO请求。在回填过程中，你可能会看到如下状态：\n\n```\nbackfill_wait: 表明回填动作被挂起，并没有执行。\n\nbackfill：表明回填动作正在执行。\n\nbackfill_too_full：表明当OSD收到回填请求时，由于OSD已经满了不能再回填PG了。 \n\nimcomplete: 当一个PG不能被回填时，这个PG会被认为是不完整的。同样，Ceph提供了一系列的参数来限制回填动作，包括osd_max_backfills：OSD最大回填PG数。\n\nsd_backfill_full_ratio：当OSD容量达到默认的85%是拒绝回填请求。osd_backfill_retry_interval:字面意思。\nRemmapped   当Acting集合里面的PG组合发生变化时，数据从旧的集合迁移到新的集合中。这段时间可能比较久，新集合的主OSD在迁移完之前不能响应请求。所以新主OSD会要求旧主OSD继续服务指导PG迁移完成。一旦数据迁移完成，新主OSD就会生效接受请求。\n```\n\n### Stale\nCeph使用心跳来确保主机和进程都在运行，OSD进程如果不能周期性的发送心跳包，那么PG就会变成stuck状态。默认情况下，OSD每半秒钟汇报一次PG，up thru,boot, failure statistics等信息，要比心跳包更会频繁一点。如果主OSD不能汇报给MON或者其他OSD汇报主OSD挂了，Monitor会将主OSD上的PG标记为stale。当启动集群后，直到peer过程完成，PG都会处于stale状态。而当集群运行了一段时间后，如果PG卡在stale状态，说明主OSD上的PG挂了或者不能给MON发送信息。\n\n### Misplaced\n有一些回填的场景：PG被临时映射到一个OSD上。而这种情况实际上不应太久，PG可能仍然处于临时位置而不是正确的位置。这种情况下个PG就是misplaced。这是因为正确的副本数存在但是有个别副本保存在错误的位置上。\n\n### Incomplete\n当一个PG被标记为incomplete,说明这个PG内容不完整或者peer失败，比如没有一个完整的OSD用来恢复数据了。\n\n### scrubbing\n清理中，pg正在做不一致性校验。\n\n### inconsistent\n不一致的，pg的副本出现不一致。比如说对象的大小不一样了。\n\n\n## 卡住的pg状态： \n```\nUnclean: 归置组里有些对象的副本数未达到期望次数，它们应该在恢复中； \nInactive: 归置组不能处理读写请求，因为它们在等着一个持有最新数据的OSD 回到up 状态； \nStale: 归置组们处于一种未知状态，因为存储它们的OSD 有一阵子没向监视器报告了（由mon osd report timeout 配置） \n为找出卡住的归置组，执行：\nceph pg dump_stuck [unclean|inactive|stale|undersized|degraded]\n```\n","slug":"ceph","published":1,"updated":"2023-01-04T07:54:06.527Z","_id":"clc5wtwoh0000n1gt0eind718","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"Ceph\"><a href=\"#Ceph\" class=\"headerlink\" title=\"Ceph\"></a>Ceph</h1><h2 id=\"OSD\"><a href=\"#OSD\" class=\"headerlink\" title=\"OSD\"></a>OSD</h2><p>通常情况下一个OSD对应一块硬盘，每个OSD都拥有一个自己的Daemon。这个Daemon负责完成OSD的所有逻辑功能，包括Monitor和其他OSD（应该说是和其他OSD的Daemon）通信以更新系统状态，与他们OSD共同完成数据存储和维护，与Client通信以完成各种数据对象操作。</p>\n<p>RADOS集群从Ceph客户端（三种类型存储客户端 + librados自定义）接收数据并存储为对象。每个对象都是文件系统的一个文件，他们被存储在OSD的存储设备上，由OSD守护进程处理存储设备上的读写操作。</p>\n<p>OSD把所有数据存储为对象。对象包含一个标识符、二进制数据和由 <code>名称/值</code> 对组成的元数据。不同类型Ceph客户端元数据语义不同。</p>\n<p>ino 待操作 File 的元数据，即文件唯一id<br>ono File 切割后某 Object 的序号<br>OID （ino，ono）</p>\n<p>一个 File 被映射成多个 Object 后，需要把每个 Object 独立的映射到一个 PG 上。</p>\n<p>Object 的 size 应当被合理设置，通常为2或4MB<br>PG也应该足够多，推荐为 OSD 的数百倍。</p>\n<p>PG -&gt; OSD 的映射是多对多的，一个 PG 由 CRUSH 算法得到一组 OSD（共n个，n可配置）。<br>这n个OSD共同负责存储和维护一个 PG 中所有的 Object。</p>\n<p>Cpeh 客户端在读写数据之前必须连个某个 ceph-mon ，获取最新的集群运行图副本。</p>\n<p>Mon 不会主动轮询各个OSD的当前状态，OSD会主动上报。MON 收到信息后，会更新 Cluster Map 信息并加以扩散。</p>\n<p>PG 与 OSD 之间的映射关系通常是不变的，除非扩容、设备损坏、修改分配策略， CRUSH 会重新分配映射关系。</p>\n<p>这些的映射关系，使得一份文件被拆分并散列分步在不同OSD上，不仅有多份文件副本，还极大优化磁盘I/O性能。</p>\n<h2 id=\"Monitor\"><a href=\"#Monitor\" class=\"headerlink\" title=\"Monitor\"></a>Monitor</h2><p>Monitor是一个独立部署的daemon进程。通过组成Monitor集群来保证自己的高可用。Monitor集群通过Paxos算法实现了自己数据的一致性。它提供了整个存储系统的节点信息等全局的配置信息。</p>\n<h2 id=\"数据平衡\"><a href=\"#数据平衡\" class=\"headerlink\" title=\"数据平衡\"></a>数据平衡</h2><p>当在集群中新添加一个OSD存储设备时，整个集群会发生数据的迁移，使得数据分布达到均衡。Ceph数据迁移的基本单位是PG，即数据迁移是将PG中的所有对象作为一个整体来迁移。</p>\n<p>迁移触发的流程为：当新加入一个OSD时，会改变系统的CRUSH Map，从而引起对象寻址过程中的第二步，PG到OSD列表的映射发生了变化，从而引发数据的迁移。</p>\n<h2 id=\"Peering\"><a href=\"#Peering\" class=\"headerlink\" title=\"Peering\"></a>Peering</h2><p>当OSD启动，或者某个OSD失效时，该OSD上的主PG会发起一个Peering的过程。Ceph的Peering过程是指一个PG内的所有副本通过PG日志来达成数据一致的过程。当Peering完成之后，该PG就可以对外提供读写服务了。此时PG的某些对象可能处于数据不一致的状态，其被标记出来，需要恢复。在写操作的过程中，遇到处于不一致的数据对象需要恢复的话，则需要等待，系统优先恢复该对象后，才能继续完成写操作。</p>\n<h2 id=\"Recovery和Backfill\"><a href=\"#Recovery和Backfill\" class=\"headerlink\" title=\"Recovery和Backfill\"></a>Recovery和Backfill</h2><p>Ceph的Recovery过程是根据在Peering的过程中产生的、依据PG日志推算出的不一致对象列表来修复其他副本上的数据。<br>Recovery过程的依据是根据PG日志来推测出不一致的对象加以修复。当某个OSD长时间失效后重新加入集群，它已经无法根据PG日志来修复，就需要执行Backfill(回填)过程。Backfill过程是通过逐一对比两个PG的对象列表来修复。当新加入一个OSD产生了数据迁移，也需要通过Backfill过程来完成。</p>\n<h2 id=\"Scrub\"><a href=\"#Scrub\" class=\"headerlink\" title=\"Scrub\"></a>Scrub</h2><p>Scrub机制用于系统检查数据的一致性。它通过在后台定期(默认每天一次)扫描，比较一个PG内的对象分别在其他OSD上的各个副本的元数据和数据来检查是否一致。根据扫描的内容分为两种，第一种是只比较对象各个副本的元数据，它代价比较小，扫描比较高效，对系统影响比较小。另一种扫描称为deep scrub，它需要进一步比较副本的数据内容检查数据是否一致。</p>\n<h2 id=\"osd的Flags\"><a href=\"#osd的Flags\" class=\"headerlink\" title=\"osd的Flags\"></a>osd的Flags</h2><h3 id=\"noin\"><a href=\"#noin\" class=\"headerlink\" title=\"noin\"></a>noin</h3><p>通常和noout一起用防止OSD up/down跳来跳去    </p>\n<h3 id=\"noout\"><a href=\"#noout\" class=\"headerlink\" title=\"noout\"></a>noout</h3><p>MON在过了300秒(mon_osd_down_out_interval)后自动将down掉的OSD标记为out，一旦out数据就会开始迁移，建议在处理故障期间设置该标记，避免数据迁移。(故障处理的第一要则设置osd noout 防止数据迁移。ceph osd set noout ,ceph osd unset noout)</p>\n<h3 id=\"noup\"><a href=\"#noup\" class=\"headerlink\" title=\"noup\"></a>noup</h3><p>通常和nodwon一起用解决OSD up/down跳来跳去</p>\n<h3 id=\"nodown\"><a href=\"#nodown\" class=\"headerlink\" title=\"nodown\"></a>nodown</h3><p>网络问题可能会影响到Ceph进程之间的心跳，有时候OSD进程还在,却被其他OSD一起举报标记为down,导致不必要的损耗，如果确定OSD进程始终正常可以设置nodown标记防止OSD被误标记为down.</p>\n<h3 id=\"full\"><a href=\"#full\" class=\"headerlink\" title=\"full\"></a>full</h3><p>如果集群快要满了，你可以预先将其设置为FULL，注意这个设置会停止写操作。(有没有效需要实际测试)</p>\n<h3 id=\"pause\"><a href=\"#pause\" class=\"headerlink\" title=\"pause\"></a>pause</h3><p>这个标记会停止一切客户端的读写，但是集群依旧保持正常运行。</p>\n<h3 id=\"nobackfill\"><a href=\"#nobackfill\" class=\"headerlink\" title=\"nobackfill\"></a>nobackfill</h3><h3 id=\"norebalance\"><a href=\"#norebalance\" class=\"headerlink\" title=\"norebalance\"></a>norebalance</h3><p>这个标记通常和上面的nobackfill和下面的norecover一起设置，在操作集群(挂掉OSD或者整个节点)时，如果不希望操作过程中数据发生恢复迁移等，可以设置这个标志，记得操作完后unset掉。</p>\n<h3 id=\"norecover\"><a href=\"#norecover\" class=\"headerlink\" title=\"norecover\"></a>norecover</h3><p>也是在操作磁盘时防止数据发生恢复。</p>\n<h3 id=\"noscrub\"><a href=\"#noscrub\" class=\"headerlink\" title=\"noscrub\"></a>noscrub</h3><p>ceph集群不做osd清理</p>\n<h3 id=\"nodeep-scrub\"><a href=\"#nodeep-scrub\" class=\"headerlink\" title=\"nodeep-scrub\"></a>nodeep-scrub</h3><p>有时候在集群恢复时，scrub操作会影响到恢复的性能，和上面的noscrub一起设置来停止scrub。一般不建议打开。</p>\n<h3 id=\"notieragent\"><a href=\"#notieragent\" class=\"headerlink\" title=\"notieragent\"></a>notieragent</h3><p>停止tier引擎查找冷数据并下刷到后端存储。</p>\n<h3 id=\"cpeh-osd-set-option\"><a href=\"#cpeh-osd-set-option\" class=\"headerlink\" title=\"cpeh osd set {option}\"></a>cpeh osd set {option}</h3><p>设置所有osd标志</p>\n<h3 id=\"ceph-osd-unset-option\"><a href=\"#ceph-osd-unset-option\" class=\"headerlink\" title=\"ceph osd unset {option}\"></a>ceph osd unset {option}</h3><p>接触所有osd标志</p>\n<h3 id=\"使用下面的命令去修复pg和osd\"><a href=\"#使用下面的命令去修复pg和osd\" class=\"headerlink\" title=\"使用下面的命令去修复pg和osd\"></a>使用下面的命令去修复pg和osd</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph osd repair ：修复一个特定的osd</span><br><span class=\"line\">ceph pg repair 修复一个特定的pg，可能会影响用户的数据，请谨慎使用。</span><br><span class=\"line\">ceph pg scrub：在指定的pg上做处理</span><br><span class=\"line\">ceph deep-scrub:在指定的pg上做深度清理。</span><br><span class=\"line\">ceph osd set pause 搬移机房时可以暂时停止读写，等待客户端读写完毕了，就可以关闭集群</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"PG的States\"><a href=\"#PG的States\" class=\"headerlink\" title=\"PG的States\"></a>PG的States</h2><h3 id=\"Creating\"><a href=\"#Creating\" class=\"headerlink\" title=\"Creating\"></a>Creating</h3><p>当创建一个池的时候，Ceph会创建一些PG(通俗点说就是在OSD上建目录)，处于创建中的PG就被标记为creating，当创建完之后，那些处于Acting集合(ceph pg map 1.0 osdmap e9395 pg 1.0 (1.0) -&gt; up [27,4,10] acting [27,4,10]，对于pg它的三副本会分布在osd.27,osd.4,osd.10上，那么这三个OSD上的pg1.0就会发生沟通，确保状态一致)的PG就会进行peer(osd互联)，当peering完成后，也就是这个PG的三副本状态一致后，这个PG就会变成active+clean状态，也就意味着客户端可以进行写入操作了。</p>\n<h3 id=\"Peering-1\"><a href=\"#Peering-1\" class=\"headerlink\" title=\"Peering\"></a>Peering</h3><p>peer过程实际上就是让三个保存同一个PG副本的OSD对保存在各自OSD上的对象状态和元数据进行协商的过程，但是呢peer完成并不意味着每个副本都保存着最新的数据。直到OSD的副本都完成写操作，Ceph才会通知客户端写操作完成。这确保了Acting集合中至少有一个副本，自最后一次成功的peer后。剩下的不好翻译因为没怎么理解。（对象和元数据的状态达成一致的过程。）</p>\n<h3 id=\"Active\"><a href=\"#Active\" class=\"headerlink\" title=\"Active\"></a>Active</h3><p>当PG完成了Peer之后，就会成为active状态，这个状态意味着主从OSD的该PG都可以提供读写了。</p>\n<h3 id=\"Clean\"><a href=\"#Clean\" class=\"headerlink\" title=\"Clean\"></a>Clean</h3><p>这个状态的意思就是主从OSD已经成功peer并且没有滞后的副本。PG的正常副本数满足集群副本数。</p>\n<h3 id=\"Degraded\"><a href=\"#Degraded\" class=\"headerlink\" title=\"Degraded\"></a>Degraded</h3><p>当客户端向一个主OSD写入一个对象时，主OSD负责向从OSD写剩下的副本， 在主OSD写完后,在从OSD向主OSD发送ack之前，这个PG均会处于降级状态。而PG处于active+degraded状态是因为一个OSD处于active状态但是这个OSD上的PG并没有保存所有的对象。当一个OSDdown了，Ceph会将这个OSD上的PG都标记为降级。当这个挂掉的OSD重新上线之后，OSD们必须重新peer。然后，客户端还是可以向一个active+degraded的PG写入的。当OSDdown掉五分钟后，集群会自动将这个OSD标为out,然后将缺少的PGremap到其他OSD上进行恢复以保证副本充足，这个五分钟的配置项是mon osd down out interval，默认值为300s。<br>PG如果丢了对象，Ceph也会将其标记为降级。你可以继续访问没丢的对象，但是不能读写已经丢失的对象了。假设有9个OSD，三副本，然后osd.8挂了，在osd.8上的PG都会被标记为降级，如果osd.8不再加回到集群那么集群就会自动恢复出那个OSD上的数据，在这个场景中，PG是降级的然后恢复完后就会变成active状态。</p>\n<h3 id=\"Recovering\"><a href=\"#Recovering\" class=\"headerlink\" title=\"Recovering\"></a>Recovering</h3><p>Ceph设计之初就考虑到了容错性，比如软硬件的错误。当一个OSD挂了，它所包含的副本内容将会落后于其他副本，当这个OSD起来之后，这个OSD的数据将会更新到当前最新的状态。这段时间，这个OSD上的PG就会被标记为recover。而recover是不容忽视的，因为有时候一个小的硬件故障可能会导致多个OSD发生一连串的问题。比如，如果一个机架或者机柜的路由挂了，会导致一大批OSD数据滞后，每个OSD在故障解决重新上线后都需要进行recover。Ceph提供了一些配置项，用来解决客户端请求和数据恢复的请求优先级问题，这些配置参考上面加粗的字体吧。</p>\n<h3 id=\"Backfilling\"><a href=\"#Backfilling\" class=\"headerlink\" title=\"Backfilling\"></a>Backfilling</h3><p>当一个新的OSD加入到集群后，CRUSH会重新规划PG将其他OSD上的部分PG迁移到这个新增的PG上。如果强制要求新OSD接受所有的PG迁入要求会极大的增加该OSD的负载。回填这个OSD允许进程在后端执行。一旦回填完成后，新的OSD将会承接IO请求。在回填过程中，你可能会看到如下状态：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">backfill_wait: 表明回填动作被挂起，并没有执行。</span><br><span class=\"line\"></span><br><span class=\"line\">backfill：表明回填动作正在执行。</span><br><span class=\"line\"></span><br><span class=\"line\">backfill_too_full：表明当OSD收到回填请求时，由于OSD已经满了不能再回填PG了。 </span><br><span class=\"line\"></span><br><span class=\"line\">imcomplete: 当一个PG不能被回填时，这个PG会被认为是不完整的。同样，Ceph提供了一系列的参数来限制回填动作，包括osd_max_backfills：OSD最大回填PG数。</span><br><span class=\"line\"></span><br><span class=\"line\">sd_backfill_full_ratio：当OSD容量达到默认的85%是拒绝回填请求。osd_backfill_retry_interval:字面意思。</span><br><span class=\"line\">Remmapped   当Acting集合里面的PG组合发生变化时，数据从旧的集合迁移到新的集合中。这段时间可能比较久，新集合的主OSD在迁移完之前不能响应请求。所以新主OSD会要求旧主OSD继续服务指导PG迁移完成。一旦数据迁移完成，新主OSD就会生效接受请求。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Stale\"><a href=\"#Stale\" class=\"headerlink\" title=\"Stale\"></a>Stale</h3><p>Ceph使用心跳来确保主机和进程都在运行，OSD进程如果不能周期性的发送心跳包，那么PG就会变成stuck状态。默认情况下，OSD每半秒钟汇报一次PG，up thru,boot, failure statistics等信息，要比心跳包更会频繁一点。如果主OSD不能汇报给MON或者其他OSD汇报主OSD挂了，Monitor会将主OSD上的PG标记为stale。当启动集群后，直到peer过程完成，PG都会处于stale状态。而当集群运行了一段时间后，如果PG卡在stale状态，说明主OSD上的PG挂了或者不能给MON发送信息。</p>\n<h3 id=\"Misplaced\"><a href=\"#Misplaced\" class=\"headerlink\" title=\"Misplaced\"></a>Misplaced</h3><p>有一些回填的场景：PG被临时映射到一个OSD上。而这种情况实际上不应太久，PG可能仍然处于临时位置而不是正确的位置。这种情况下个PG就是misplaced。这是因为正确的副本数存在但是有个别副本保存在错误的位置上。</p>\n<h3 id=\"Incomplete\"><a href=\"#Incomplete\" class=\"headerlink\" title=\"Incomplete\"></a>Incomplete</h3><p>当一个PG被标记为incomplete,说明这个PG内容不完整或者peer失败，比如没有一个完整的OSD用来恢复数据了。</p>\n<h3 id=\"scrubbing\"><a href=\"#scrubbing\" class=\"headerlink\" title=\"scrubbing\"></a>scrubbing</h3><p>清理中，pg正在做不一致性校验。</p>\n<h3 id=\"inconsistent\"><a href=\"#inconsistent\" class=\"headerlink\" title=\"inconsistent\"></a>inconsistent</h3><p>不一致的，pg的副本出现不一致。比如说对象的大小不一样了。</p>\n<h2 id=\"卡住的pg状态：\"><a href=\"#卡住的pg状态：\" class=\"headerlink\" title=\"卡住的pg状态：\"></a>卡住的pg状态：</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Unclean: 归置组里有些对象的副本数未达到期望次数，它们应该在恢复中； </span><br><span class=\"line\">Inactive: 归置组不能处理读写请求，因为它们在等着一个持有最新数据的OSD 回到up 状态； </span><br><span class=\"line\">Stale: 归置组们处于一种未知状态，因为存储它们的OSD 有一阵子没向监视器报告了（由mon osd report timeout 配置） </span><br><span class=\"line\">为找出卡住的归置组，执行：</span><br><span class=\"line\">ceph pg dump_stuck [unclean|inactive|stale|undersized|degraded]</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Ceph\"><a href=\"#Ceph\" class=\"headerlink\" title=\"Ceph\"></a>Ceph</h1><h2 id=\"OSD\"><a href=\"#OSD\" class=\"headerlink\" title=\"OSD\"></a>OSD</h2><p>通常情况下一个OSD对应一块硬盘，每个OSD都拥有一个自己的Daemon。这个Daemon负责完成OSD的所有逻辑功能，包括Monitor和其他OSD（应该说是和其他OSD的Daemon）通信以更新系统状态，与他们OSD共同完成数据存储和维护，与Client通信以完成各种数据对象操作。</p>\n<p>RADOS集群从Ceph客户端（三种类型存储客户端 + librados自定义）接收数据并存储为对象。每个对象都是文件系统的一个文件，他们被存储在OSD的存储设备上，由OSD守护进程处理存储设备上的读写操作。</p>\n<p>OSD把所有数据存储为对象。对象包含一个标识符、二进制数据和由 <code>名称/值</code> 对组成的元数据。不同类型Ceph客户端元数据语义不同。</p>\n<p>ino 待操作 File 的元数据，即文件唯一id<br>ono File 切割后某 Object 的序号<br>OID （ino，ono）</p>\n<p>一个 File 被映射成多个 Object 后，需要把每个 Object 独立的映射到一个 PG 上。</p>\n<p>Object 的 size 应当被合理设置，通常为2或4MB<br>PG也应该足够多，推荐为 OSD 的数百倍。</p>\n<p>PG -&gt; OSD 的映射是多对多的，一个 PG 由 CRUSH 算法得到一组 OSD（共n个，n可配置）。<br>这n个OSD共同负责存储和维护一个 PG 中所有的 Object。</p>\n<p>Cpeh 客户端在读写数据之前必须连个某个 ceph-mon ，获取最新的集群运行图副本。</p>\n<p>Mon 不会主动轮询各个OSD的当前状态，OSD会主动上报。MON 收到信息后，会更新 Cluster Map 信息并加以扩散。</p>\n<p>PG 与 OSD 之间的映射关系通常是不变的，除非扩容、设备损坏、修改分配策略， CRUSH 会重新分配映射关系。</p>\n<p>这些的映射关系，使得一份文件被拆分并散列分步在不同OSD上，不仅有多份文件副本，还极大优化磁盘I/O性能。</p>\n<h2 id=\"Monitor\"><a href=\"#Monitor\" class=\"headerlink\" title=\"Monitor\"></a>Monitor</h2><p>Monitor是一个独立部署的daemon进程。通过组成Monitor集群来保证自己的高可用。Monitor集群通过Paxos算法实现了自己数据的一致性。它提供了整个存储系统的节点信息等全局的配置信息。</p>\n<h2 id=\"数据平衡\"><a href=\"#数据平衡\" class=\"headerlink\" title=\"数据平衡\"></a>数据平衡</h2><p>当在集群中新添加一个OSD存储设备时，整个集群会发生数据的迁移，使得数据分布达到均衡。Ceph数据迁移的基本单位是PG，即数据迁移是将PG中的所有对象作为一个整体来迁移。</p>\n<p>迁移触发的流程为：当新加入一个OSD时，会改变系统的CRUSH Map，从而引起对象寻址过程中的第二步，PG到OSD列表的映射发生了变化，从而引发数据的迁移。</p>\n<h2 id=\"Peering\"><a href=\"#Peering\" class=\"headerlink\" title=\"Peering\"></a>Peering</h2><p>当OSD启动，或者某个OSD失效时，该OSD上的主PG会发起一个Peering的过程。Ceph的Peering过程是指一个PG内的所有副本通过PG日志来达成数据一致的过程。当Peering完成之后，该PG就可以对外提供读写服务了。此时PG的某些对象可能处于数据不一致的状态，其被标记出来，需要恢复。在写操作的过程中，遇到处于不一致的数据对象需要恢复的话，则需要等待，系统优先恢复该对象后，才能继续完成写操作。</p>\n<h2 id=\"Recovery和Backfill\"><a href=\"#Recovery和Backfill\" class=\"headerlink\" title=\"Recovery和Backfill\"></a>Recovery和Backfill</h2><p>Ceph的Recovery过程是根据在Peering的过程中产生的、依据PG日志推算出的不一致对象列表来修复其他副本上的数据。<br>Recovery过程的依据是根据PG日志来推测出不一致的对象加以修复。当某个OSD长时间失效后重新加入集群，它已经无法根据PG日志来修复，就需要执行Backfill(回填)过程。Backfill过程是通过逐一对比两个PG的对象列表来修复。当新加入一个OSD产生了数据迁移，也需要通过Backfill过程来完成。</p>\n<h2 id=\"Scrub\"><a href=\"#Scrub\" class=\"headerlink\" title=\"Scrub\"></a>Scrub</h2><p>Scrub机制用于系统检查数据的一致性。它通过在后台定期(默认每天一次)扫描，比较一个PG内的对象分别在其他OSD上的各个副本的元数据和数据来检查是否一致。根据扫描的内容分为两种，第一种是只比较对象各个副本的元数据，它代价比较小，扫描比较高效，对系统影响比较小。另一种扫描称为deep scrub，它需要进一步比较副本的数据内容检查数据是否一致。</p>\n<h2 id=\"osd的Flags\"><a href=\"#osd的Flags\" class=\"headerlink\" title=\"osd的Flags\"></a>osd的Flags</h2><h3 id=\"noin\"><a href=\"#noin\" class=\"headerlink\" title=\"noin\"></a>noin</h3><p>通常和noout一起用防止OSD up/down跳来跳去    </p>\n<h3 id=\"noout\"><a href=\"#noout\" class=\"headerlink\" title=\"noout\"></a>noout</h3><p>MON在过了300秒(mon_osd_down_out_interval)后自动将down掉的OSD标记为out，一旦out数据就会开始迁移，建议在处理故障期间设置该标记，避免数据迁移。(故障处理的第一要则设置osd noout 防止数据迁移。ceph osd set noout ,ceph osd unset noout)</p>\n<h3 id=\"noup\"><a href=\"#noup\" class=\"headerlink\" title=\"noup\"></a>noup</h3><p>通常和nodwon一起用解决OSD up/down跳来跳去</p>\n<h3 id=\"nodown\"><a href=\"#nodown\" class=\"headerlink\" title=\"nodown\"></a>nodown</h3><p>网络问题可能会影响到Ceph进程之间的心跳，有时候OSD进程还在,却被其他OSD一起举报标记为down,导致不必要的损耗，如果确定OSD进程始终正常可以设置nodown标记防止OSD被误标记为down.</p>\n<h3 id=\"full\"><a href=\"#full\" class=\"headerlink\" title=\"full\"></a>full</h3><p>如果集群快要满了，你可以预先将其设置为FULL，注意这个设置会停止写操作。(有没有效需要实际测试)</p>\n<h3 id=\"pause\"><a href=\"#pause\" class=\"headerlink\" title=\"pause\"></a>pause</h3><p>这个标记会停止一切客户端的读写，但是集群依旧保持正常运行。</p>\n<h3 id=\"nobackfill\"><a href=\"#nobackfill\" class=\"headerlink\" title=\"nobackfill\"></a>nobackfill</h3><h3 id=\"norebalance\"><a href=\"#norebalance\" class=\"headerlink\" title=\"norebalance\"></a>norebalance</h3><p>这个标记通常和上面的nobackfill和下面的norecover一起设置，在操作集群(挂掉OSD或者整个节点)时，如果不希望操作过程中数据发生恢复迁移等，可以设置这个标志，记得操作完后unset掉。</p>\n<h3 id=\"norecover\"><a href=\"#norecover\" class=\"headerlink\" title=\"norecover\"></a>norecover</h3><p>也是在操作磁盘时防止数据发生恢复。</p>\n<h3 id=\"noscrub\"><a href=\"#noscrub\" class=\"headerlink\" title=\"noscrub\"></a>noscrub</h3><p>ceph集群不做osd清理</p>\n<h3 id=\"nodeep-scrub\"><a href=\"#nodeep-scrub\" class=\"headerlink\" title=\"nodeep-scrub\"></a>nodeep-scrub</h3><p>有时候在集群恢复时，scrub操作会影响到恢复的性能，和上面的noscrub一起设置来停止scrub。一般不建议打开。</p>\n<h3 id=\"notieragent\"><a href=\"#notieragent\" class=\"headerlink\" title=\"notieragent\"></a>notieragent</h3><p>停止tier引擎查找冷数据并下刷到后端存储。</p>\n<h3 id=\"cpeh-osd-set-option\"><a href=\"#cpeh-osd-set-option\" class=\"headerlink\" title=\"cpeh osd set {option}\"></a>cpeh osd set {option}</h3><p>设置所有osd标志</p>\n<h3 id=\"ceph-osd-unset-option\"><a href=\"#ceph-osd-unset-option\" class=\"headerlink\" title=\"ceph osd unset {option}\"></a>ceph osd unset {option}</h3><p>接触所有osd标志</p>\n<h3 id=\"使用下面的命令去修复pg和osd\"><a href=\"#使用下面的命令去修复pg和osd\" class=\"headerlink\" title=\"使用下面的命令去修复pg和osd\"></a>使用下面的命令去修复pg和osd</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph osd repair ：修复一个特定的osd</span><br><span class=\"line\">ceph pg repair 修复一个特定的pg，可能会影响用户的数据，请谨慎使用。</span><br><span class=\"line\">ceph pg scrub：在指定的pg上做处理</span><br><span class=\"line\">ceph deep-scrub:在指定的pg上做深度清理。</span><br><span class=\"line\">ceph osd set pause 搬移机房时可以暂时停止读写，等待客户端读写完毕了，就可以关闭集群</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"PG的States\"><a href=\"#PG的States\" class=\"headerlink\" title=\"PG的States\"></a>PG的States</h2><h3 id=\"Creating\"><a href=\"#Creating\" class=\"headerlink\" title=\"Creating\"></a>Creating</h3><p>当创建一个池的时候，Ceph会创建一些PG(通俗点说就是在OSD上建目录)，处于创建中的PG就被标记为creating，当创建完之后，那些处于Acting集合(ceph pg map 1.0 osdmap e9395 pg 1.0 (1.0) -&gt; up [27,4,10] acting [27,4,10]，对于pg它的三副本会分布在osd.27,osd.4,osd.10上，那么这三个OSD上的pg1.0就会发生沟通，确保状态一致)的PG就会进行peer(osd互联)，当peering完成后，也就是这个PG的三副本状态一致后，这个PG就会变成active+clean状态，也就意味着客户端可以进行写入操作了。</p>\n<h3 id=\"Peering-1\"><a href=\"#Peering-1\" class=\"headerlink\" title=\"Peering\"></a>Peering</h3><p>peer过程实际上就是让三个保存同一个PG副本的OSD对保存在各自OSD上的对象状态和元数据进行协商的过程，但是呢peer完成并不意味着每个副本都保存着最新的数据。直到OSD的副本都完成写操作，Ceph才会通知客户端写操作完成。这确保了Acting集合中至少有一个副本，自最后一次成功的peer后。剩下的不好翻译因为没怎么理解。（对象和元数据的状态达成一致的过程。）</p>\n<h3 id=\"Active\"><a href=\"#Active\" class=\"headerlink\" title=\"Active\"></a>Active</h3><p>当PG完成了Peer之后，就会成为active状态，这个状态意味着主从OSD的该PG都可以提供读写了。</p>\n<h3 id=\"Clean\"><a href=\"#Clean\" class=\"headerlink\" title=\"Clean\"></a>Clean</h3><p>这个状态的意思就是主从OSD已经成功peer并且没有滞后的副本。PG的正常副本数满足集群副本数。</p>\n<h3 id=\"Degraded\"><a href=\"#Degraded\" class=\"headerlink\" title=\"Degraded\"></a>Degraded</h3><p>当客户端向一个主OSD写入一个对象时，主OSD负责向从OSD写剩下的副本， 在主OSD写完后,在从OSD向主OSD发送ack之前，这个PG均会处于降级状态。而PG处于active+degraded状态是因为一个OSD处于active状态但是这个OSD上的PG并没有保存所有的对象。当一个OSDdown了，Ceph会将这个OSD上的PG都标记为降级。当这个挂掉的OSD重新上线之后，OSD们必须重新peer。然后，客户端还是可以向一个active+degraded的PG写入的。当OSDdown掉五分钟后，集群会自动将这个OSD标为out,然后将缺少的PGremap到其他OSD上进行恢复以保证副本充足，这个五分钟的配置项是mon osd down out interval，默认值为300s。<br>PG如果丢了对象，Ceph也会将其标记为降级。你可以继续访问没丢的对象，但是不能读写已经丢失的对象了。假设有9个OSD，三副本，然后osd.8挂了，在osd.8上的PG都会被标记为降级，如果osd.8不再加回到集群那么集群就会自动恢复出那个OSD上的数据，在这个场景中，PG是降级的然后恢复完后就会变成active状态。</p>\n<h3 id=\"Recovering\"><a href=\"#Recovering\" class=\"headerlink\" title=\"Recovering\"></a>Recovering</h3><p>Ceph设计之初就考虑到了容错性，比如软硬件的错误。当一个OSD挂了，它所包含的副本内容将会落后于其他副本，当这个OSD起来之后，这个OSD的数据将会更新到当前最新的状态。这段时间，这个OSD上的PG就会被标记为recover。而recover是不容忽视的，因为有时候一个小的硬件故障可能会导致多个OSD发生一连串的问题。比如，如果一个机架或者机柜的路由挂了，会导致一大批OSD数据滞后，每个OSD在故障解决重新上线后都需要进行recover。Ceph提供了一些配置项，用来解决客户端请求和数据恢复的请求优先级问题，这些配置参考上面加粗的字体吧。</p>\n<h3 id=\"Backfilling\"><a href=\"#Backfilling\" class=\"headerlink\" title=\"Backfilling\"></a>Backfilling</h3><p>当一个新的OSD加入到集群后，CRUSH会重新规划PG将其他OSD上的部分PG迁移到这个新增的PG上。如果强制要求新OSD接受所有的PG迁入要求会极大的增加该OSD的负载。回填这个OSD允许进程在后端执行。一旦回填完成后，新的OSD将会承接IO请求。在回填过程中，你可能会看到如下状态：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">backfill_wait: 表明回填动作被挂起，并没有执行。</span><br><span class=\"line\"></span><br><span class=\"line\">backfill：表明回填动作正在执行。</span><br><span class=\"line\"></span><br><span class=\"line\">backfill_too_full：表明当OSD收到回填请求时，由于OSD已经满了不能再回填PG了。 </span><br><span class=\"line\"></span><br><span class=\"line\">imcomplete: 当一个PG不能被回填时，这个PG会被认为是不完整的。同样，Ceph提供了一系列的参数来限制回填动作，包括osd_max_backfills：OSD最大回填PG数。</span><br><span class=\"line\"></span><br><span class=\"line\">sd_backfill_full_ratio：当OSD容量达到默认的85%是拒绝回填请求。osd_backfill_retry_interval:字面意思。</span><br><span class=\"line\">Remmapped   当Acting集合里面的PG组合发生变化时，数据从旧的集合迁移到新的集合中。这段时间可能比较久，新集合的主OSD在迁移完之前不能响应请求。所以新主OSD会要求旧主OSD继续服务指导PG迁移完成。一旦数据迁移完成，新主OSD就会生效接受请求。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"Stale\"><a href=\"#Stale\" class=\"headerlink\" title=\"Stale\"></a>Stale</h3><p>Ceph使用心跳来确保主机和进程都在运行，OSD进程如果不能周期性的发送心跳包，那么PG就会变成stuck状态。默认情况下，OSD每半秒钟汇报一次PG，up thru,boot, failure statistics等信息，要比心跳包更会频繁一点。如果主OSD不能汇报给MON或者其他OSD汇报主OSD挂了，Monitor会将主OSD上的PG标记为stale。当启动集群后，直到peer过程完成，PG都会处于stale状态。而当集群运行了一段时间后，如果PG卡在stale状态，说明主OSD上的PG挂了或者不能给MON发送信息。</p>\n<h3 id=\"Misplaced\"><a href=\"#Misplaced\" class=\"headerlink\" title=\"Misplaced\"></a>Misplaced</h3><p>有一些回填的场景：PG被临时映射到一个OSD上。而这种情况实际上不应太久，PG可能仍然处于临时位置而不是正确的位置。这种情况下个PG就是misplaced。这是因为正确的副本数存在但是有个别副本保存在错误的位置上。</p>\n<h3 id=\"Incomplete\"><a href=\"#Incomplete\" class=\"headerlink\" title=\"Incomplete\"></a>Incomplete</h3><p>当一个PG被标记为incomplete,说明这个PG内容不完整或者peer失败，比如没有一个完整的OSD用来恢复数据了。</p>\n<h3 id=\"scrubbing\"><a href=\"#scrubbing\" class=\"headerlink\" title=\"scrubbing\"></a>scrubbing</h3><p>清理中，pg正在做不一致性校验。</p>\n<h3 id=\"inconsistent\"><a href=\"#inconsistent\" class=\"headerlink\" title=\"inconsistent\"></a>inconsistent</h3><p>不一致的，pg的副本出现不一致。比如说对象的大小不一样了。</p>\n<h2 id=\"卡住的pg状态：\"><a href=\"#卡住的pg状态：\" class=\"headerlink\" title=\"卡住的pg状态：\"></a>卡住的pg状态：</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Unclean: 归置组里有些对象的副本数未达到期望次数，它们应该在恢复中； </span><br><span class=\"line\">Inactive: 归置组不能处理读写请求，因为它们在等着一个持有最新数据的OSD 回到up 状态； </span><br><span class=\"line\">Stale: 归置组们处于一种未知状态，因为存储它们的OSD 有一阵子没向监视器报告了（由mon osd report timeout 配置） </span><br><span class=\"line\">为找出卡住的归置组，执行：</span><br><span class=\"line\">ceph pg dump_stuck [unclean|inactive|stale|undersized|degraded]</span><br></pre></td></tr></table></figure>\n"},{"title":"单词备忘录","date":"2023-01-04T03:21:09.000Z","_content":"\n# 2023-01-04\n\n```\nallocate 分配\nrescheduling 重新调度\ndetected 检测到\nskew 偏斜\n```\n\n# 2023-01-05\n\n```\n```\n","source":"_posts/word.md","raw":"---\ntitle: 单词备忘录\ndate: 2023-01-04 11:21:09\ntags:\n---\n\n# 2023-01-04\n\n```\nallocate 分配\nrescheduling 重新调度\ndetected 检测到\nskew 偏斜\n```\n\n# 2023-01-05\n\n```\n```\n","slug":"word","published":1,"updated":"2023-01-04T07:58:18.937Z","_id":"clch3mxam0000l0gthiazab15","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"2023-01-04\"><a href=\"#2023-01-04\" class=\"headerlink\" title=\"2023-01-04\"></a>2023-01-04</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">allocate 分配</span><br><span class=\"line\">rescheduling 重新调度</span><br><span class=\"line\">detected 检测到</span><br><span class=\"line\">skew 偏斜</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2023-01-05\"><a href=\"#2023-01-05\" class=\"headerlink\" title=\"2023-01-05\"></a>2023-01-05</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"2023-01-04\"><a href=\"#2023-01-04\" class=\"headerlink\" title=\"2023-01-04\"></a>2023-01-04</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">allocate 分配</span><br><span class=\"line\">rescheduling 重新调度</span><br><span class=\"line\">detected 检测到</span><br><span class=\"line\">skew 偏斜</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"2023-01-05\"><a href=\"#2023-01-05\" class=\"headerlink\" title=\"2023-01-05\"></a>2023-01-05</h1><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br></pre></td></tr></table></figure>\n"},{"title":"disk","date":"2023-01-09T05:27:49.000Z","_content":"\n# 磁盘io分析\n\n工具 iostat\n\n## CPU 参数说明\n\n```\n%user：CPU处在用户模式下的时间百分比\n\n%nice：CPU处在带NICE值的用户模式下的时间百分比。\n\n%system：CPU处在系统模式下的时间百分比。\n\n%iowait：CPU等待输入输出完成时间的百分比。\n\n%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。\n\n%idle：CPU空闲时间百分比。\n```\n\n```\n如果%iowait的值过高，表示硬盘存在I/O瓶颈\n\n如果%idle值高，表示CPU较空闲\n\n如果%idle值高但系统响应慢时，可能是CPU等待分配内存，应加大内存容量。\n\n如果%idle值持续低于cpu核数，表明CPU处理能力相对较低，系统中最需要解决的资源是CPU。\n```\n\n## Device 参数说明\n\n```\ntps：该设备每秒的传输次数\n\nkB_read/s：每秒从设备（drive expressed）读取的数据量；\n\nkB_wrtn/s：每秒向设备（drive expressed）写入的数据量；\n\nkB_read：  读取的总数据量；\n\nkB_wrtn：写入的总数量数据量；\n```\n\n# 带宽测试\n\n工具： iperf3\n\n","source":"_posts/disk.md","raw":"---\ntitle: disk\ndate: 2023-01-09 13:27:49\ntags:\n---\n\n# 磁盘io分析\n\n工具 iostat\n\n## CPU 参数说明\n\n```\n%user：CPU处在用户模式下的时间百分比\n\n%nice：CPU处在带NICE值的用户模式下的时间百分比。\n\n%system：CPU处在系统模式下的时间百分比。\n\n%iowait：CPU等待输入输出完成时间的百分比。\n\n%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。\n\n%idle：CPU空闲时间百分比。\n```\n\n```\n如果%iowait的值过高，表示硬盘存在I/O瓶颈\n\n如果%idle值高，表示CPU较空闲\n\n如果%idle值高但系统响应慢时，可能是CPU等待分配内存，应加大内存容量。\n\n如果%idle值持续低于cpu核数，表明CPU处理能力相对较低，系统中最需要解决的资源是CPU。\n```\n\n## Device 参数说明\n\n```\ntps：该设备每秒的传输次数\n\nkB_read/s：每秒从设备（drive expressed）读取的数据量；\n\nkB_wrtn/s：每秒向设备（drive expressed）写入的数据量；\n\nkB_read：  读取的总数据量；\n\nkB_wrtn：写入的总数量数据量；\n```\n\n# 带宽测试\n\n工具： iperf3\n\n","slug":"disk","published":1,"updated":"2023-01-09T06:25:55.315Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clcof7m0g00009bgt0phz8oym","content":"<h1 id=\"磁盘io分析\"><a href=\"#磁盘io分析\" class=\"headerlink\" title=\"磁盘io分析\"></a>磁盘io分析</h1><p>工具 iostat</p>\n<h2 id=\"CPU-参数说明\"><a href=\"#CPU-参数说明\" class=\"headerlink\" title=\"CPU 参数说明\"></a>CPU 参数说明</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%user：CPU处在用户模式下的时间百分比</span><br><span class=\"line\"></span><br><span class=\"line\">%nice：CPU处在带NICE值的用户模式下的时间百分比。</span><br><span class=\"line\"></span><br><span class=\"line\">%system：CPU处在系统模式下的时间百分比。</span><br><span class=\"line\"></span><br><span class=\"line\">%iowait：CPU等待输入输出完成时间的百分比。</span><br><span class=\"line\"></span><br><span class=\"line\">%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。</span><br><span class=\"line\"></span><br><span class=\"line\">%idle：CPU空闲时间百分比。</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">如果%iowait的值过高，表示硬盘存在I/O瓶颈</span><br><span class=\"line\"></span><br><span class=\"line\">如果%idle值高，表示CPU较空闲</span><br><span class=\"line\"></span><br><span class=\"line\">如果%idle值高但系统响应慢时，可能是CPU等待分配内存，应加大内存容量。</span><br><span class=\"line\"></span><br><span class=\"line\">如果%idle值持续低于cpu核数，表明CPU处理能力相对较低，系统中最需要解决的资源是CPU。</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Device-参数说明\"><a href=\"#Device-参数说明\" class=\"headerlink\" title=\"Device 参数说明\"></a>Device 参数说明</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tps：该设备每秒的传输次数</span><br><span class=\"line\"></span><br><span class=\"line\">kB_read/s：每秒从设备（drive expressed）读取的数据量；</span><br><span class=\"line\"></span><br><span class=\"line\">kB_wrtn/s：每秒向设备（drive expressed）写入的数据量；</span><br><span class=\"line\"></span><br><span class=\"line\">kB_read：  读取的总数据量；</span><br><span class=\"line\"></span><br><span class=\"line\">kB_wrtn：写入的总数量数据量；</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"带宽测试\"><a href=\"#带宽测试\" class=\"headerlink\" title=\"带宽测试\"></a>带宽测试</h1><p>工具： iperf3</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"磁盘io分析\"><a href=\"#磁盘io分析\" class=\"headerlink\" title=\"磁盘io分析\"></a>磁盘io分析</h1><p>工具 iostat</p>\n<h2 id=\"CPU-参数说明\"><a href=\"#CPU-参数说明\" class=\"headerlink\" title=\"CPU 参数说明\"></a>CPU 参数说明</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%user：CPU处在用户模式下的时间百分比</span><br><span class=\"line\"></span><br><span class=\"line\">%nice：CPU处在带NICE值的用户模式下的时间百分比。</span><br><span class=\"line\"></span><br><span class=\"line\">%system：CPU处在系统模式下的时间百分比。</span><br><span class=\"line\"></span><br><span class=\"line\">%iowait：CPU等待输入输出完成时间的百分比。</span><br><span class=\"line\"></span><br><span class=\"line\">%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。</span><br><span class=\"line\"></span><br><span class=\"line\">%idle：CPU空闲时间百分比。</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">如果%iowait的值过高，表示硬盘存在I/O瓶颈</span><br><span class=\"line\"></span><br><span class=\"line\">如果%idle值高，表示CPU较空闲</span><br><span class=\"line\"></span><br><span class=\"line\">如果%idle值高但系统响应慢时，可能是CPU等待分配内存，应加大内存容量。</span><br><span class=\"line\"></span><br><span class=\"line\">如果%idle值持续低于cpu核数，表明CPU处理能力相对较低，系统中最需要解决的资源是CPU。</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Device-参数说明\"><a href=\"#Device-参数说明\" class=\"headerlink\" title=\"Device 参数说明\"></a>Device 参数说明</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tps：该设备每秒的传输次数</span><br><span class=\"line\"></span><br><span class=\"line\">kB_read/s：每秒从设备（drive expressed）读取的数据量；</span><br><span class=\"line\"></span><br><span class=\"line\">kB_wrtn/s：每秒向设备（drive expressed）写入的数据量；</span><br><span class=\"line\"></span><br><span class=\"line\">kB_read：  读取的总数据量；</span><br><span class=\"line\"></span><br><span class=\"line\">kB_wrtn：写入的总数量数据量；</span><br></pre></td></tr></table></figure>\n\n<h1 id=\"带宽测试\"><a href=\"#带宽测试\" class=\"headerlink\" title=\"带宽测试\"></a>带宽测试</h1><p>工具： iperf3</p>\n"},{"title":"快捷键备忘录","date":"2023-01-14T03:14:51.000Z","_content":"\n# 快捷键备忘录\n\n## vim\n\n## linux shell\n\n```\nctrl+u 删除命令行开始至光标处\nctrl+k 删除光标处至命令行结尾\nctrl+a 光标移动到最前面\nctrl+e 光标移动到最后面\n```\n\n## vscode\n\n```\nctrl+shift+k   删除整行  \nctrl+l         复制整行\n```","source":"_posts/快捷键备忘录.md","raw":"---\ntitle: 快捷键备忘录\ndate: 2023-01-14 11:14:51\ntags:\n---\n\n# 快捷键备忘录\n\n## vim\n\n## linux shell\n\n```\nctrl+u 删除命令行开始至光标处\nctrl+k 删除光标处至命令行结尾\nctrl+a 光标移动到最前面\nctrl+e 光标移动到最后面\n```\n\n## vscode\n\n```\nctrl+shift+k   删除整行  \nctrl+l         复制整行\n```","slug":"快捷键备忘录","published":1,"updated":"2023-01-15T06:14:29.793Z","_id":"clcve36ng0001eigth0g374ae","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"快捷键备忘录\"><a href=\"#快捷键备忘录\" class=\"headerlink\" title=\"快捷键备忘录\"></a>快捷键备忘录</h1><h2 id=\"vim\"><a href=\"#vim\" class=\"headerlink\" title=\"vim\"></a>vim</h2><h2 id=\"linux-shell\"><a href=\"#linux-shell\" class=\"headerlink\" title=\"linux shell\"></a>linux shell</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ctrl+u 删除命令行开始至光标处</span><br><span class=\"line\">ctrl+k 删除光标处至命令行结尾</span><br><span class=\"line\">ctrl+a 光标移动到最前面</span><br><span class=\"line\">ctrl+e 光标移动到最后面</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"vscode\"><a href=\"#vscode\" class=\"headerlink\" title=\"vscode\"></a>vscode</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ctrl+shift+k   删除整行  </span><br><span class=\"line\">ctrl+l         复制整行</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"快捷键备忘录\"><a href=\"#快捷键备忘录\" class=\"headerlink\" title=\"快捷键备忘录\"></a>快捷键备忘录</h1><h2 id=\"vim\"><a href=\"#vim\" class=\"headerlink\" title=\"vim\"></a>vim</h2><h2 id=\"linux-shell\"><a href=\"#linux-shell\" class=\"headerlink\" title=\"linux shell\"></a>linux shell</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ctrl+u 删除命令行开始至光标处</span><br><span class=\"line\">ctrl+k 删除光标处至命令行结尾</span><br><span class=\"line\">ctrl+a 光标移动到最前面</span><br><span class=\"line\">ctrl+e 光标移动到最后面</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"vscode\"><a href=\"#vscode\" class=\"headerlink\" title=\"vscode\"></a>vscode</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ctrl+shift+k   删除整行  </span><br><span class=\"line\">ctrl+l         复制整行</span><br></pre></td></tr></table></figure>"},{"title":"crash工具使用","date":"2023-01-14T03:13:19.000Z","_content":"\ncrash是redhat的工程师开发的，主要用来离线分析linux内核转存文件(即 coredump，保存了进程某一时刻的运行状态，它在进程发生问题时产生)，它整合了gdb工具，功能非常强大。可以查看堆栈，dmesg日志，内核数据结构，反汇编等等。crash支持多种工具生成的转存文件格式，如kdump，LKCD，netdump和diskdump，而且还可以分析虚拟机Xen和Kvm上生成的内核转存文件。同时crash还可以调试运行时系统，直接运行crash即可，ubuntu下内核映象存放在/proc/kcore。\n\n# 安装\n\n## centos\n\n```bash\nyum install crash\n```\n\n## 加载coredump\n\ncrash在加载内核转存文件是会输出系统基本信息，如出问题的进程（crond - 21230），系统内存大小（32 GB），系统架构（x86_64）等等，可以看到这个dump是crond触发的一个panic系统崩溃。\n\n\n```bash\ncrash /lib/debug/lib/modules/3.10.0-327.36.3.el7.x86_64/vmlinux vmcore\n```\n\n![系统基本信息](/pictures/crash-1.png)\n\n## 查看堆栈\n\n一般可以先查看堆栈（bt），看看系统死在什么地方，进而确定调查方向。可以看到 #5 位置打印出很多寄存器的地址，exception RIP表示出问题时候执行的指令。\n\nnetlink_compare发生kernel panic（当内核无法正确加载，无法正常启动或崩溃时）并输出以下回溯。\n\n![堆栈图](/pictures/crash-2.png)\n\n\n查询资料后，定位到这是 `kernel Linux 3.10.0-327.36.3.el7.x86_64` 的bug，[详细描述参见](https://www.dell.com/support/kbdoc/zh-cn/000171350/kernel-panic-in-rhel-7-2-kernel-3-10-0-327-el7-x86-64) 或 https://bugs.centos.org/view.php?id=12012 ，该bug在 7.3 kernel (3.10.0-514.el7)后修复。\n\n## 其他\n\n### kmem\n\n```\nkmem -i           查看内存的使用统计信息\nkmem -g           查看page flags的定义\nkmem -g 0x201     将指定的数字翻译为page的flags\nkmem -p <page *>  查看指定page的信息\n```\n\n### 基本信息含义\n\n```\nKERNEL:    内核崩溃时运行的 Kernel ELF 文件.\nDUMPFILE:  内核转储文件.\nCPUS:      机器 CPU 的数量.\nDATE:      系统崩溃的时间.\nUPTIME:    系统启动到系统奔溃的时间.\nLOAD AVERAGE:\nTASKS:     系统崩溃时内存中的任务数.\nNODENAME:  崩溃系统的主机名.\nRELEASE:   崩溃内核的版本号.\nVERSION:   崩溃内核的版本号.\nMACHINE:   CPU 架构和主频信息.\nMEMORY:    崩溃主机的物理内存.\nPANIC:     崩溃类型.\nPID:       导致内核崩溃的进程号.\nCOMMAND:   导致内核崩溃的命令.\nTASK:\nCPU:\nSTATE:\n```\n\n### bt\n    \n```\nbt 打印内核奔溃 CPU 上运行 TASK 的堆栈\nbt -a 打印内核奔溃时所有 CPU 上 TASK 的堆栈\nbt -g\nbt -p 只打印发生内核 PANIC CPU 上 TASK 的堆栈\nbt -r 打印内核奔溃 CPU 上 TASK 的堆栈内容\nbt -t 打印内核崩溃 CPU 上 TASK 的函数调用栈\nbt -T 打印内核崩溃 CPU 上 TASK 堆栈中所有的调用函数\nbt -l 打印内核崩溃 CPU 上 TASK 堆栈栈帧函数的文件及行号\nbt -e 打印内核崩溃 CPU 上 TASK 堆栈中可能异常的帧\nbt -E 打印所有 CPU 的中断堆栈\nbt -f 打印内核崩溃 CPU 上 TASK 堆栈栈帧的内容\nbt -F[F] 打印内核崩溃 CPU 上 TASK 栈帧中 SLAB CACHE 对象信息\nbt -o 以老式堆栈方式打印内核崩溃 CPU 上 TASK 的堆栈\nbt -O 将 CRASH 堆栈打印模式设置为老式堆栈模式\nbt [-R symbol] 显示包含 symbol 的堆栈信息\nbt [-I ip]\nbt [-S sp] 从 SP 处开始打印内核崩溃 CPU 上 TASK 的堆栈\nbt pid 按 PID 打印 TASK 的堆栈\nbt taskp 按 TASK 的 task_struct 十六进制值来打印堆栈\nbt -c cpu 打印指定 CPU 上 TASK 的堆栈\n```\n\n### 进程状态\n\n```\nTASK_RUNNING : 进程处于可运行状态，但并不意味着进程已经实际上已分配到 CPU ，它可能会一直等到调度器选中它。该状态只是确保进程一旦被 CPU 选中时立马可以运行，而无需等待外部事件。\nTASK_INTERRUPTIBLE : 这是针对等待某事件或其他资源而睡眠的进程设置的。在内核发送信号给该进程时表明等待的事件已经发生或资源已经可用，进程状态变为 TASK_RUNNING，此时只要被调度器选中就立即可恢复运行。\nTASK_UNINTERRUPTIBLE : 处于此状态，不能由外部信号唤醒，只能由内核亲自唤醒。\nTASK_STOPPED : 表示进程特意停止运行。比如在调试程序时，进程被调试器暂停下来。\nTASK_TRACED : 本来不属于进程状态，用于从停止的进程中，将当前被调试的那些进程与常规进程区分开来。\n```\n\n下面常量既可以用于 struct task_struct 的进程状态字段，也可以用于 exit_state 字段(该字段明确的用于退出进程)：\n\n```\nEXIT_ZOMBIE : 僵尸状态。\nEXIT_DEAD : 处于该状态， 表示 wait 系统调用已经发出，而进程完全从系统移除之前的状态。只有多个线程对同一个进程发出 wait 调用时，该状态才有意义(为了防止其他执行线程在同一个进程也执行wait()类系统调用，而把进程的状态由僵死状态(EXIT_ZOMBIE)改为撤销状态(EXIT_DEAD)。\n```\n\n### 其他\n\n```\nps           查看系统崩溃时在运行的所有进程\nset 3016     查看进程 3016 的状态\nbt -f        打印函数栈数据\ndmesg        查看系统崩溃时dmesg的信息\n```","source":"_posts/一次mysql虚拟机crash分析.md","raw":"---\ntitle: crash工具使用\ndate: 2023-01-14 11:13:19\ntags:\n---\n\ncrash是redhat的工程师开发的，主要用来离线分析linux内核转存文件(即 coredump，保存了进程某一时刻的运行状态，它在进程发生问题时产生)，它整合了gdb工具，功能非常强大。可以查看堆栈，dmesg日志，内核数据结构，反汇编等等。crash支持多种工具生成的转存文件格式，如kdump，LKCD，netdump和diskdump，而且还可以分析虚拟机Xen和Kvm上生成的内核转存文件。同时crash还可以调试运行时系统，直接运行crash即可，ubuntu下内核映象存放在/proc/kcore。\n\n# 安装\n\n## centos\n\n```bash\nyum install crash\n```\n\n## 加载coredump\n\ncrash在加载内核转存文件是会输出系统基本信息，如出问题的进程（crond - 21230），系统内存大小（32 GB），系统架构（x86_64）等等，可以看到这个dump是crond触发的一个panic系统崩溃。\n\n\n```bash\ncrash /lib/debug/lib/modules/3.10.0-327.36.3.el7.x86_64/vmlinux vmcore\n```\n\n![系统基本信息](/pictures/crash-1.png)\n\n## 查看堆栈\n\n一般可以先查看堆栈（bt），看看系统死在什么地方，进而确定调查方向。可以看到 #5 位置打印出很多寄存器的地址，exception RIP表示出问题时候执行的指令。\n\nnetlink_compare发生kernel panic（当内核无法正确加载，无法正常启动或崩溃时）并输出以下回溯。\n\n![堆栈图](/pictures/crash-2.png)\n\n\n查询资料后，定位到这是 `kernel Linux 3.10.0-327.36.3.el7.x86_64` 的bug，[详细描述参见](https://www.dell.com/support/kbdoc/zh-cn/000171350/kernel-panic-in-rhel-7-2-kernel-3-10-0-327-el7-x86-64) 或 https://bugs.centos.org/view.php?id=12012 ，该bug在 7.3 kernel (3.10.0-514.el7)后修复。\n\n## 其他\n\n### kmem\n\n```\nkmem -i           查看内存的使用统计信息\nkmem -g           查看page flags的定义\nkmem -g 0x201     将指定的数字翻译为page的flags\nkmem -p <page *>  查看指定page的信息\n```\n\n### 基本信息含义\n\n```\nKERNEL:    内核崩溃时运行的 Kernel ELF 文件.\nDUMPFILE:  内核转储文件.\nCPUS:      机器 CPU 的数量.\nDATE:      系统崩溃的时间.\nUPTIME:    系统启动到系统奔溃的时间.\nLOAD AVERAGE:\nTASKS:     系统崩溃时内存中的任务数.\nNODENAME:  崩溃系统的主机名.\nRELEASE:   崩溃内核的版本号.\nVERSION:   崩溃内核的版本号.\nMACHINE:   CPU 架构和主频信息.\nMEMORY:    崩溃主机的物理内存.\nPANIC:     崩溃类型.\nPID:       导致内核崩溃的进程号.\nCOMMAND:   导致内核崩溃的命令.\nTASK:\nCPU:\nSTATE:\n```\n\n### bt\n    \n```\nbt 打印内核奔溃 CPU 上运行 TASK 的堆栈\nbt -a 打印内核奔溃时所有 CPU 上 TASK 的堆栈\nbt -g\nbt -p 只打印发生内核 PANIC CPU 上 TASK 的堆栈\nbt -r 打印内核奔溃 CPU 上 TASK 的堆栈内容\nbt -t 打印内核崩溃 CPU 上 TASK 的函数调用栈\nbt -T 打印内核崩溃 CPU 上 TASK 堆栈中所有的调用函数\nbt -l 打印内核崩溃 CPU 上 TASK 堆栈栈帧函数的文件及行号\nbt -e 打印内核崩溃 CPU 上 TASK 堆栈中可能异常的帧\nbt -E 打印所有 CPU 的中断堆栈\nbt -f 打印内核崩溃 CPU 上 TASK 堆栈栈帧的内容\nbt -F[F] 打印内核崩溃 CPU 上 TASK 栈帧中 SLAB CACHE 对象信息\nbt -o 以老式堆栈方式打印内核崩溃 CPU 上 TASK 的堆栈\nbt -O 将 CRASH 堆栈打印模式设置为老式堆栈模式\nbt [-R symbol] 显示包含 symbol 的堆栈信息\nbt [-I ip]\nbt [-S sp] 从 SP 处开始打印内核崩溃 CPU 上 TASK 的堆栈\nbt pid 按 PID 打印 TASK 的堆栈\nbt taskp 按 TASK 的 task_struct 十六进制值来打印堆栈\nbt -c cpu 打印指定 CPU 上 TASK 的堆栈\n```\n\n### 进程状态\n\n```\nTASK_RUNNING : 进程处于可运行状态，但并不意味着进程已经实际上已分配到 CPU ，它可能会一直等到调度器选中它。该状态只是确保进程一旦被 CPU 选中时立马可以运行，而无需等待外部事件。\nTASK_INTERRUPTIBLE : 这是针对等待某事件或其他资源而睡眠的进程设置的。在内核发送信号给该进程时表明等待的事件已经发生或资源已经可用，进程状态变为 TASK_RUNNING，此时只要被调度器选中就立即可恢复运行。\nTASK_UNINTERRUPTIBLE : 处于此状态，不能由外部信号唤醒，只能由内核亲自唤醒。\nTASK_STOPPED : 表示进程特意停止运行。比如在调试程序时，进程被调试器暂停下来。\nTASK_TRACED : 本来不属于进程状态，用于从停止的进程中，将当前被调试的那些进程与常规进程区分开来。\n```\n\n下面常量既可以用于 struct task_struct 的进程状态字段，也可以用于 exit_state 字段(该字段明确的用于退出进程)：\n\n```\nEXIT_ZOMBIE : 僵尸状态。\nEXIT_DEAD : 处于该状态， 表示 wait 系统调用已经发出，而进程完全从系统移除之前的状态。只有多个线程对同一个进程发出 wait 调用时，该状态才有意义(为了防止其他执行线程在同一个进程也执行wait()类系统调用，而把进程的状态由僵死状态(EXIT_ZOMBIE)改为撤销状态(EXIT_DEAD)。\n```\n\n### 其他\n\n```\nps           查看系统崩溃时在运行的所有进程\nset 3016     查看进程 3016 的状态\nbt -f        打印函数栈数据\ndmesg        查看系统崩溃时dmesg的信息\n```","slug":"一次mysql虚拟机crash分析","published":1,"updated":"2023-01-14T08:14:52.763Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clcvoer6800002egt9qeg1rfs","content":"<p>crash是redhat的工程师开发的，主要用来离线分析linux内核转存文件(即 coredump，保存了进程某一时刻的运行状态，它在进程发生问题时产生)，它整合了gdb工具，功能非常强大。可以查看堆栈，dmesg日志，内核数据结构，反汇编等等。crash支持多种工具生成的转存文件格式，如kdump，LKCD，netdump和diskdump，而且还可以分析虚拟机Xen和Kvm上生成的内核转存文件。同时crash还可以调试运行时系统，直接运行crash即可，ubuntu下内核映象存放在/proc/kcore。</p>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><h2 id=\"centos\"><a href=\"#centos\" class=\"headerlink\" title=\"centos\"></a>centos</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install crash</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"加载coredump\"><a href=\"#加载coredump\" class=\"headerlink\" title=\"加载coredump\"></a>加载coredump</h2><p>crash在加载内核转存文件是会输出系统基本信息，如出问题的进程（crond - 21230），系统内存大小（32 GB），系统架构（x86_64）等等，可以看到这个dump是crond触发的一个panic系统崩溃。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">crash /lib/debug/lib/modules/3.10.0-327.36.3.el7.x86_64/vmlinux vmcore</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/pictures/crash-1.png\" alt=\"系统基本信息\"></p>\n<h2 id=\"查看堆栈\"><a href=\"#查看堆栈\" class=\"headerlink\" title=\"查看堆栈\"></a>查看堆栈</h2><p>一般可以先查看堆栈（bt），看看系统死在什么地方，进而确定调查方向。可以看到 #5 位置打印出很多寄存器的地址，exception RIP表示出问题时候执行的指令。</p>\n<p>netlink_compare发生kernel panic（当内核无法正确加载，无法正常启动或崩溃时）并输出以下回溯。</p>\n<p><img src=\"/pictures/crash-2.png\" alt=\"堆栈图\"></p>\n<p>查询资料后，定位到这是 <code>kernel Linux 3.10.0-327.36.3.el7.x86_64</code> 的bug，<a href=\"https://www.dell.com/support/kbdoc/zh-cn/000171350/kernel-panic-in-rhel-7-2-kernel-3-10-0-327-el7-x86-64\">详细描述参见</a> 或 <a href=\"https://bugs.centos.org/view.php?id=12012\">https://bugs.centos.org/view.php?id=12012</a> ，该bug在 7.3 kernel (3.10.0-514.el7)后修复。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><h3 id=\"kmem\"><a href=\"#kmem\" class=\"headerlink\" title=\"kmem\"></a>kmem</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kmem -i           查看内存的使用统计信息</span><br><span class=\"line\">kmem -g           查看page flags的定义</span><br><span class=\"line\">kmem -g 0x201     将指定的数字翻译为page的flags</span><br><span class=\"line\">kmem -p &lt;page *&gt;  查看指定page的信息</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"基本信息含义\"><a href=\"#基本信息含义\" class=\"headerlink\" title=\"基本信息含义\"></a>基本信息含义</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">KERNEL:    内核崩溃时运行的 Kernel ELF 文件.</span><br><span class=\"line\">DUMPFILE:  内核转储文件.</span><br><span class=\"line\">CPUS:      机器 CPU 的数量.</span><br><span class=\"line\">DATE:      系统崩溃的时间.</span><br><span class=\"line\">UPTIME:    系统启动到系统奔溃的时间.</span><br><span class=\"line\">LOAD AVERAGE:</span><br><span class=\"line\">TASKS:     系统崩溃时内存中的任务数.</span><br><span class=\"line\">NODENAME:  崩溃系统的主机名.</span><br><span class=\"line\">RELEASE:   崩溃内核的版本号.</span><br><span class=\"line\">VERSION:   崩溃内核的版本号.</span><br><span class=\"line\">MACHINE:   CPU 架构和主频信息.</span><br><span class=\"line\">MEMORY:    崩溃主机的物理内存.</span><br><span class=\"line\">PANIC:     崩溃类型.</span><br><span class=\"line\">PID:       导致内核崩溃的进程号.</span><br><span class=\"line\">COMMAND:   导致内核崩溃的命令.</span><br><span class=\"line\">TASK:</span><br><span class=\"line\">CPU:</span><br><span class=\"line\">STATE:</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"bt\"><a href=\"#bt\" class=\"headerlink\" title=\"bt\"></a>bt</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bt 打印内核奔溃 CPU 上运行 TASK 的堆栈</span><br><span class=\"line\">bt -a 打印内核奔溃时所有 CPU 上 TASK 的堆栈</span><br><span class=\"line\">bt -g</span><br><span class=\"line\">bt -p 只打印发生内核 PANIC CPU 上 TASK 的堆栈</span><br><span class=\"line\">bt -r 打印内核奔溃 CPU 上 TASK 的堆栈内容</span><br><span class=\"line\">bt -t 打印内核崩溃 CPU 上 TASK 的函数调用栈</span><br><span class=\"line\">bt -T 打印内核崩溃 CPU 上 TASK 堆栈中所有的调用函数</span><br><span class=\"line\">bt -l 打印内核崩溃 CPU 上 TASK 堆栈栈帧函数的文件及行号</span><br><span class=\"line\">bt -e 打印内核崩溃 CPU 上 TASK 堆栈中可能异常的帧</span><br><span class=\"line\">bt -E 打印所有 CPU 的中断堆栈</span><br><span class=\"line\">bt -f 打印内核崩溃 CPU 上 TASK 堆栈栈帧的内容</span><br><span class=\"line\">bt -F[F] 打印内核崩溃 CPU 上 TASK 栈帧中 SLAB CACHE 对象信息</span><br><span class=\"line\">bt -o 以老式堆栈方式打印内核崩溃 CPU 上 TASK 的堆栈</span><br><span class=\"line\">bt -O 将 CRASH 堆栈打印模式设置为老式堆栈模式</span><br><span class=\"line\">bt [-R symbol] 显示包含 symbol 的堆栈信息</span><br><span class=\"line\">bt [-I ip]</span><br><span class=\"line\">bt [-S sp] 从 SP 处开始打印内核崩溃 CPU 上 TASK 的堆栈</span><br><span class=\"line\">bt pid 按 PID 打印 TASK 的堆栈</span><br><span class=\"line\">bt taskp 按 TASK 的 task_struct 十六进制值来打印堆栈</span><br><span class=\"line\">bt -c cpu 打印指定 CPU 上 TASK 的堆栈</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"进程状态\"><a href=\"#进程状态\" class=\"headerlink\" title=\"进程状态\"></a>进程状态</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TASK_RUNNING : 进程处于可运行状态，但并不意味着进程已经实际上已分配到 CPU ，它可能会一直等到调度器选中它。该状态只是确保进程一旦被 CPU 选中时立马可以运行，而无需等待外部事件。</span><br><span class=\"line\">TASK_INTERRUPTIBLE : 这是针对等待某事件或其他资源而睡眠的进程设置的。在内核发送信号给该进程时表明等待的事件已经发生或资源已经可用，进程状态变为 TASK_RUNNING，此时只要被调度器选中就立即可恢复运行。</span><br><span class=\"line\">TASK_UNINTERRUPTIBLE : 处于此状态，不能由外部信号唤醒，只能由内核亲自唤醒。</span><br><span class=\"line\">TASK_STOPPED : 表示进程特意停止运行。比如在调试程序时，进程被调试器暂停下来。</span><br><span class=\"line\">TASK_TRACED : 本来不属于进程状态，用于从停止的进程中，将当前被调试的那些进程与常规进程区分开来。</span><br></pre></td></tr></table></figure>\n\n<p>下面常量既可以用于 struct task_struct 的进程状态字段，也可以用于 exit_state 字段(该字段明确的用于退出进程)：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">EXIT_ZOMBIE : 僵尸状态。</span><br><span class=\"line\">EXIT_DEAD : 处于该状态， 表示 wait 系统调用已经发出，而进程完全从系统移除之前的状态。只有多个线程对同一个进程发出 wait 调用时，该状态才有意义(为了防止其他执行线程在同一个进程也执行wait()类系统调用，而把进程的状态由僵死状态(EXIT_ZOMBIE)改为撤销状态(EXIT_DEAD)。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"其他-1\"><a href=\"#其他-1\" class=\"headerlink\" title=\"其他\"></a>其他</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ps           查看系统崩溃时在运行的所有进程</span><br><span class=\"line\">set 3016     查看进程 3016 的状态</span><br><span class=\"line\">bt -f        打印函数栈数据</span><br><span class=\"line\">dmesg        查看系统崩溃时dmesg的信息</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p>crash是redhat的工程师开发的，主要用来离线分析linux内核转存文件(即 coredump，保存了进程某一时刻的运行状态，它在进程发生问题时产生)，它整合了gdb工具，功能非常强大。可以查看堆栈，dmesg日志，内核数据结构，反汇编等等。crash支持多种工具生成的转存文件格式，如kdump，LKCD，netdump和diskdump，而且还可以分析虚拟机Xen和Kvm上生成的内核转存文件。同时crash还可以调试运行时系统，直接运行crash即可，ubuntu下内核映象存放在/proc/kcore。</p>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><h2 id=\"centos\"><a href=\"#centos\" class=\"headerlink\" title=\"centos\"></a>centos</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yum install crash</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"加载coredump\"><a href=\"#加载coredump\" class=\"headerlink\" title=\"加载coredump\"></a>加载coredump</h2><p>crash在加载内核转存文件是会输出系统基本信息，如出问题的进程（crond - 21230），系统内存大小（32 GB），系统架构（x86_64）等等，可以看到这个dump是crond触发的一个panic系统崩溃。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">crash /lib/debug/lib/modules/3.10.0-327.36.3.el7.x86_64/vmlinux vmcore</span><br></pre></td></tr></table></figure>\n\n<p><img src=\"/pictures/crash-1.png\" alt=\"系统基本信息\"></p>\n<h2 id=\"查看堆栈\"><a href=\"#查看堆栈\" class=\"headerlink\" title=\"查看堆栈\"></a>查看堆栈</h2><p>一般可以先查看堆栈（bt），看看系统死在什么地方，进而确定调查方向。可以看到 #5 位置打印出很多寄存器的地址，exception RIP表示出问题时候执行的指令。</p>\n<p>netlink_compare发生kernel panic（当内核无法正确加载，无法正常启动或崩溃时）并输出以下回溯。</p>\n<p><img src=\"/pictures/crash-2.png\" alt=\"堆栈图\"></p>\n<p>查询资料后，定位到这是 <code>kernel Linux 3.10.0-327.36.3.el7.x86_64</code> 的bug，<a href=\"https://www.dell.com/support/kbdoc/zh-cn/000171350/kernel-panic-in-rhel-7-2-kernel-3-10-0-327-el7-x86-64\">详细描述参见</a> 或 <a href=\"https://bugs.centos.org/view.php?id=12012\">https://bugs.centos.org/view.php?id=12012</a> ，该bug在 7.3 kernel (3.10.0-514.el7)后修复。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><h3 id=\"kmem\"><a href=\"#kmem\" class=\"headerlink\" title=\"kmem\"></a>kmem</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kmem -i           查看内存的使用统计信息</span><br><span class=\"line\">kmem -g           查看page flags的定义</span><br><span class=\"line\">kmem -g 0x201     将指定的数字翻译为page的flags</span><br><span class=\"line\">kmem -p &lt;page *&gt;  查看指定page的信息</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"基本信息含义\"><a href=\"#基本信息含义\" class=\"headerlink\" title=\"基本信息含义\"></a>基本信息含义</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">KERNEL:    内核崩溃时运行的 Kernel ELF 文件.</span><br><span class=\"line\">DUMPFILE:  内核转储文件.</span><br><span class=\"line\">CPUS:      机器 CPU 的数量.</span><br><span class=\"line\">DATE:      系统崩溃的时间.</span><br><span class=\"line\">UPTIME:    系统启动到系统奔溃的时间.</span><br><span class=\"line\">LOAD AVERAGE:</span><br><span class=\"line\">TASKS:     系统崩溃时内存中的任务数.</span><br><span class=\"line\">NODENAME:  崩溃系统的主机名.</span><br><span class=\"line\">RELEASE:   崩溃内核的版本号.</span><br><span class=\"line\">VERSION:   崩溃内核的版本号.</span><br><span class=\"line\">MACHINE:   CPU 架构和主频信息.</span><br><span class=\"line\">MEMORY:    崩溃主机的物理内存.</span><br><span class=\"line\">PANIC:     崩溃类型.</span><br><span class=\"line\">PID:       导致内核崩溃的进程号.</span><br><span class=\"line\">COMMAND:   导致内核崩溃的命令.</span><br><span class=\"line\">TASK:</span><br><span class=\"line\">CPU:</span><br><span class=\"line\">STATE:</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"bt\"><a href=\"#bt\" class=\"headerlink\" title=\"bt\"></a>bt</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bt 打印内核奔溃 CPU 上运行 TASK 的堆栈</span><br><span class=\"line\">bt -a 打印内核奔溃时所有 CPU 上 TASK 的堆栈</span><br><span class=\"line\">bt -g</span><br><span class=\"line\">bt -p 只打印发生内核 PANIC CPU 上 TASK 的堆栈</span><br><span class=\"line\">bt -r 打印内核奔溃 CPU 上 TASK 的堆栈内容</span><br><span class=\"line\">bt -t 打印内核崩溃 CPU 上 TASK 的函数调用栈</span><br><span class=\"line\">bt -T 打印内核崩溃 CPU 上 TASK 堆栈中所有的调用函数</span><br><span class=\"line\">bt -l 打印内核崩溃 CPU 上 TASK 堆栈栈帧函数的文件及行号</span><br><span class=\"line\">bt -e 打印内核崩溃 CPU 上 TASK 堆栈中可能异常的帧</span><br><span class=\"line\">bt -E 打印所有 CPU 的中断堆栈</span><br><span class=\"line\">bt -f 打印内核崩溃 CPU 上 TASK 堆栈栈帧的内容</span><br><span class=\"line\">bt -F[F] 打印内核崩溃 CPU 上 TASK 栈帧中 SLAB CACHE 对象信息</span><br><span class=\"line\">bt -o 以老式堆栈方式打印内核崩溃 CPU 上 TASK 的堆栈</span><br><span class=\"line\">bt -O 将 CRASH 堆栈打印模式设置为老式堆栈模式</span><br><span class=\"line\">bt [-R symbol] 显示包含 symbol 的堆栈信息</span><br><span class=\"line\">bt [-I ip]</span><br><span class=\"line\">bt [-S sp] 从 SP 处开始打印内核崩溃 CPU 上 TASK 的堆栈</span><br><span class=\"line\">bt pid 按 PID 打印 TASK 的堆栈</span><br><span class=\"line\">bt taskp 按 TASK 的 task_struct 十六进制值来打印堆栈</span><br><span class=\"line\">bt -c cpu 打印指定 CPU 上 TASK 的堆栈</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"进程状态\"><a href=\"#进程状态\" class=\"headerlink\" title=\"进程状态\"></a>进程状态</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TASK_RUNNING : 进程处于可运行状态，但并不意味着进程已经实际上已分配到 CPU ，它可能会一直等到调度器选中它。该状态只是确保进程一旦被 CPU 选中时立马可以运行，而无需等待外部事件。</span><br><span class=\"line\">TASK_INTERRUPTIBLE : 这是针对等待某事件或其他资源而睡眠的进程设置的。在内核发送信号给该进程时表明等待的事件已经发生或资源已经可用，进程状态变为 TASK_RUNNING，此时只要被调度器选中就立即可恢复运行。</span><br><span class=\"line\">TASK_UNINTERRUPTIBLE : 处于此状态，不能由外部信号唤醒，只能由内核亲自唤醒。</span><br><span class=\"line\">TASK_STOPPED : 表示进程特意停止运行。比如在调试程序时，进程被调试器暂停下来。</span><br><span class=\"line\">TASK_TRACED : 本来不属于进程状态，用于从停止的进程中，将当前被调试的那些进程与常规进程区分开来。</span><br></pre></td></tr></table></figure>\n\n<p>下面常量既可以用于 struct task_struct 的进程状态字段，也可以用于 exit_state 字段(该字段明确的用于退出进程)：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">EXIT_ZOMBIE : 僵尸状态。</span><br><span class=\"line\">EXIT_DEAD : 处于该状态， 表示 wait 系统调用已经发出，而进程完全从系统移除之前的状态。只有多个线程对同一个进程发出 wait 调用时，该状态才有意义(为了防止其他执行线程在同一个进程也执行wait()类系统调用，而把进程的状态由僵死状态(EXIT_ZOMBIE)改为撤销状态(EXIT_DEAD)。</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"其他-1\"><a href=\"#其他-1\" class=\"headerlink\" title=\"其他\"></a>其他</h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ps           查看系统崩溃时在运行的所有进程</span><br><span class=\"line\">set 3016     查看进程 3016 的状态</span><br><span class=\"line\">bt -f        打印函数栈数据</span><br><span class=\"line\">dmesg        查看系统崩溃时dmesg的信息</span><br></pre></td></tr></table></figure>"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}